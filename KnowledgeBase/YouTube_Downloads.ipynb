{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7042052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "install_deps = False\n",
    "if install_deps:\n",
    "    #!curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh \n",
    "    #!source \"$HOME/.cargo/env\"\n",
    "    #!sudo apt-get install libssl-dev\n",
    "    !pip install -U requests moviepy pytube tqdm pinecone-client[grpc] git+https://github.com/naver/splade.git sentence_transformers openai-whisper PyPDF2 openai\n",
    "    !pip install -U transformers    \n",
    "    !pip install -U git+https://github.com/openai/whisper.git \n",
    "    \n",
    "import os\n",
    "import requests\n",
    "\n",
    "from moviepy.editor import *\n",
    "from pytube import YouTube\n",
    "#from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# transcription to use huggingface whisper large v2\n",
    "import json\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# pdf document reading\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# vector db\n",
    "import pinecone # pip install pinecone-client[grpc]\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from splade.models.transformer_rep import Splade # pip install git+https://github.com/naver/splade.git\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# conversational interface\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532e142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64964f88",
   "metadata": {},
   "source": [
    "Set up the YouTube Data API v3:\n",
    "\n",
    "Go to the Google Cloud Console: https://console.cloud.google.com/\n",
    "Create a new project.\n",
    "Enable the YouTube Data API v3 for that project.\n",
    "Create credentials (an API key) for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "773c06fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_video_links_from_channel(channel_name, api_key):\n",
    "    # This gets the channel ID based on the username\n",
    "    channel_data_url = f\"https://www.googleapis.com/youtube/v3/channels?part=id&forUsername={channel_name}&key={api_key}\"\n",
    "    print(channel_data_url)\n",
    "    channel_id = requests.get(channel_data_url).json()['items'][0]['id']\n",
    "\n",
    "    # Use the API to get all video IDs from the channel\n",
    "    #search_url = f\"https://www.googleapis.com/youtube/v3/search?part=id&channelId={channel_id}&maxResults={max_videos}&type=video&key={api_key}\"\n",
    "    search_url = f\"https://www.googleapis.com/youtube/v3/search?part=id&channelId={channel_id}&maxResults=200&type=video&key={api_key}\"\n",
    "    print(search_url)\n",
    "    video_ids = [item['id']['videoId'] for item in requests.get(search_url).json()['items']]\n",
    "\n",
    "    # Convert video IDs to full YouTube URLs\n",
    "    full_links = [f\"https://www.youtube.com/watch?v={video_id}\" for video_id in video_ids]\n",
    "\n",
    "    return video_ids, full_links\n",
    "\n",
    "def download_videos_from_links(video_ids, video_links, download_path='.'):\n",
    "    titles = []\n",
    "    for count, link in enumerate(tqdm(video_links, desc=\"Downloading videos\", unit=\"video\")):\n",
    "        yt = YouTube(link)\n",
    "        stream = yt.streams.get_highest_resolution()\n",
    "        titles.append([video_ids[count], video_links[count], yt.title])\n",
    "        stream.download(output_path=download_path, filename = f\"{video_ids[count]}.mp4\")\n",
    "    return(titles)\n",
    "\n",
    "def download_youtube_video(video_id, path='.'):\n",
    "    \"\"\"\n",
    "    Downloads a YouTube video given its ID.\n",
    "\n",
    "    :param video_id: str, The ID of the YouTube video.\n",
    "    :param path: str, The path where the video will be saved.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Constructing YouTube video URL\n",
    "        video_url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "        \n",
    "        # Creating a YouTube object with the video URL\n",
    "        yt = YouTube(video_url)\n",
    "        \n",
    "        # Getting the highest resolution stream (with audio if available)\n",
    "        video_stream = yt.streams.filter(file_extension='mp4').get_highest_resolution()\n",
    "        \n",
    "        # If the stream is None, try to get any mp4 stream\n",
    "        if video_stream is None:\n",
    "            video_stream = yt.streams.filter(file_extension='mp4').first()\n",
    "        \n",
    "        # Downloading the video\n",
    "        if video_stream:\n",
    "            video_stream.download(output_path=path)\n",
    "            print(f\"The video {video_id} has been downloaded successfully!\")\n",
    "        else:\n",
    "            print(\"No suitable stream found.\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        \n",
    "def extract_audio_from_mp4(directory):\n",
    "    # Get a list of all .mp4 files in the specified directory\n",
    "    mp4_files = [file for file in os.listdir(directory) if file.endswith('.mp4')]\n",
    "\n",
    "    for mp4_file in mp4_files:\n",
    "        video_path = os.path.join(directory, mp4_file)\n",
    "        audio_path = os.path.join(directory, mp4_file.replace('.mp4', '.wav'))\n",
    "\n",
    "        # Load the video file\n",
    "        video = VideoFileClip(video_path)\n",
    "\n",
    "        # Extract audio and save as .wav\n",
    "        video.audio.write_audiofile(audio_path, codec='pcm_s16le')\n",
    "\n",
    "        \n",
    "def list_files_by_extensions(directory, extensions):\n",
    "    # Convert extensions to lower case for consistent checking\n",
    "    extensions = [ext.lower() for ext in extensions]\n",
    "    \n",
    "    # Use a list comprehension to get files with the specified extensions in the directory\n",
    "    files = [os.path.join(directory, file) for file in os.listdir(directory) if file.split('.')[-1].lower() in extensions]\n",
    "    \n",
    "    return files\n",
    "\n",
    "def get_text_from_data(start, end, data):\n",
    "    text = \"\"\n",
    "    for i in range(start,end):\n",
    "        text += data[i]['text']+' '\n",
    "    return text\n",
    "\n",
    "# for text files\n",
    "limit = 512\n",
    "def chunker(contexts: list):\n",
    "    chunks = []\n",
    "    all_contexts = contexts.split('.')\n",
    "    chunk = []\n",
    "    for context in all_contexts:\n",
    "        chunk.append(context)\n",
    "        if len(chunk) >= 3 and len('.'.join(chunk)) > limit:\n",
    "            # surpassed limit so add to chunks and reset\n",
    "            chunks.append('.'.join(chunk).strip()+'.')\n",
    "            # add some overlap between passages\n",
    "            chunk = chunk[-2:]\n",
    "    # if we finish and still have a chunk, add it\n",
    "    if chunk is not None:\n",
    "        chunks.append('.'.join(chunk))\n",
    "    return chunks\n",
    "\n",
    "def get_chunked_text(pdf_filename):\n",
    "    reader = PdfReader(pdf_filename)\n",
    "    # read data from the file and put them into a variable called raw_text\n",
    "    raw_text = ''\n",
    "    for i, page in enumerate(reader.pages):\n",
    "        text = page.extract_text()\n",
    "        if text:\n",
    "            raw_text += text\n",
    "    texts = chunker(raw_text)\n",
    "    return texts\n",
    "\n",
    "def get_files_recursive(dir_path):\n",
    "    files = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(dir_path):\n",
    "        files.extend(filenames)\n",
    "        for dirname in dirnames:\n",
    "            dir = os.path.join(dirpath, dirname)\n",
    "            files.extend(get_files_recursive(dir))\n",
    "    return files\n",
    "\n",
    "def read_file_data(document_path, PDF_filenames):\n",
    "    file_data=[]\n",
    "    text=[]\n",
    "    for pdf_filename in PDF_filenames:\n",
    "        text = get_chunked_text(document_path+\"/\"+pdf_filename)\n",
    "        for i, context in enumerate(text):\n",
    "            file_data.append({\n",
    "                'id': f\"{pdf_filename}-{i}\",\n",
    "                'context': context,\n",
    "                'filename': pdf_filename\n",
    "            })\n",
    "    return file_data\n",
    "\n",
    "def builder(records: list):\n",
    "    ids = [x['id'] for x in records]\n",
    "    contexts = [x['text'] for x in records]\n",
    "    urls = [x['url'] for x in records]\n",
    "    channels = [x['name'] for x in records]\n",
    "    titles = [x['title'] for x in records]\n",
    "    # create dense vecs\n",
    "    dense_vecs = dense_model.encode(contexts).tolist()\n",
    "    # create sparse vecs\n",
    "    input_ids = tokenizer(\n",
    "        contexts, return_tensors='pt',\n",
    "        padding=True, truncation=True\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        sparse_vecs = sparse_model(\n",
    "            d_kwargs=input_ids.to(device)\n",
    "        )['d_rep'].squeeze()\n",
    "    # convert to upsert format\n",
    "    upserts = []\n",
    "    for _id, dense_vec, sparse_vec, context, url, channel, title in zip(ids, dense_vecs, sparse_vecs, contexts, urls, channels, titles):\n",
    "        # extract columns where there are non-zero weights\n",
    "        indices = sparse_vec.nonzero().squeeze().cpu().tolist()  # positions\n",
    "        values = sparse_vec[indices].cpu().tolist()  # weights/scores\n",
    "        # build sparse values dictionary\n",
    "        sparse_values = {\n",
    "            \"indices\": indices,\n",
    "            \"values\": values\n",
    "        }\n",
    "        # build metadata struct\n",
    "        # build metadata struct\n",
    "        metadata = {\n",
    "            'context': context,\n",
    "            'url': url,\n",
    "            'channel': channel,\n",
    "            'title': title\n",
    "        }\n",
    "        # append all to upserts list as pinecone.Vector (or GRPCVector)\n",
    "        upserts.append({\n",
    "            'id': _id,\n",
    "            'values': dense_vec,\n",
    "            'sparse_values': sparse_values,\n",
    "            'metadata': metadata\n",
    "        })\n",
    "    return upserts\n",
    "\n",
    "def builder_files(records: list):\n",
    "    ids = [x['id'] for x in records]\n",
    "    contexts = [x['context'] for x in records]\n",
    "    filenames = [x['filename'] for x in records]\n",
    "    # create dense vecs\n",
    "    dense_vecs = dense_model.encode(contexts).tolist()\n",
    "    # create sparse vecs\n",
    "    input_ids = tokenizer(\n",
    "        contexts, return_tensors='pt',\n",
    "        padding=True, truncation=True\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        sparse_vecs = sparse_model(\n",
    "            d_kwargs=input_ids.to(device)\n",
    "        )['d_rep'].squeeze()\n",
    "    # convert to upsert format\n",
    "    upserts = []\n",
    "    for _id, dense_vec, sparse_vec, context, filename in zip(ids, dense_vecs, sparse_vecs, contexts, filenames):\n",
    "        # extract columns where there are non-zero weights\n",
    "        indices = sparse_vec.nonzero().squeeze().cpu().tolist()  # positions\n",
    "        values = sparse_vec[indices].cpu().tolist()  # weights/scores\n",
    "        # build sparse values dictionary\n",
    "        sparse_values = {\n",
    "            \"indices\": indices,\n",
    "            \"values\": values\n",
    "        }\n",
    "        # build metadata struct\n",
    "        metadata = {'context': context,\n",
    "                    'filename': filename}\n",
    "        # append all to upserts list as pinecone.Vector (or GRPCVector)\n",
    "        upserts.append({\n",
    "            'id': _id,\n",
    "            'values': dense_vec,\n",
    "            'sparse_values': sparse_values,\n",
    "            'metadata': metadata\n",
    "        })\n",
    "    return upserts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "116bbcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_name = \"vidIQ\"\n",
    "download_path = f\"./downloads/{channel_name}\"\n",
    "download_videos = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7c5500",
   "metadata": {},
   "source": [
    "## Download videos from YouTube\n",
    "### Extract audio\n",
    "### Transcribe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c24ed882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model and processor\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "pipe = pipeline(\n",
    "  \"automatic-speech-recognition\",\n",
    "  model=\"openai/whisper-large-v2\",\n",
    "  chunk_length_s=30,\n",
    "  device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3ce0f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.googleapis.com/youtube/v3/channels?part=id&forUsername=vidIQ&key=AIzaSyAIIY6OsTws8dTfoyxNmJLmnfmH2f859Fw\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m channel_name \u001b[38;5;129;01min\u001b[39;00m channel_names:\n\u001b[1;32m      3\u001b[0m     download_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./downloads/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchannel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     video_ids, video_links \u001b[38;5;241m=\u001b[39m get_all_video_links_from_channel(channel_name, api_key)\n\u001b[1;32m      5\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(download_path, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m download_videos:\n",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m, in \u001b[0;36mget_all_video_links_from_channel\u001b[0;34m(channel_name, api_key)\u001b[0m\n\u001b[1;32m      3\u001b[0m channel_data_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.googleapis.com/youtube/v3/channels?part=id&forUsername=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchannel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&key=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(channel_data_url)\n\u001b[0;32m----> 5\u001b[0m channel_id \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(channel_data_url)\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitems\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Use the API to get all video IDs from the channel\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#search_url = f\"https://www.googleapis.com/youtube/v3/search?part=id&channelId={channel_id}&maxResults={max_videos}&type=video&key={api_key}\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m search_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.googleapis.com/youtube/v3/search?part=id&channelId=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchannel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&maxResults=200&type=video&key=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapi_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'items'"
     ]
    }
   ],
   "source": [
    "channel_names = ['vidIQ']\n",
    "for channel_name in channel_names:\n",
    "    download_path = f\"./downloads/{channel_name}\"\n",
    "    video_ids, video_links = get_all_video_links_from_channel(channel_name, api_key)\n",
    "    os.makedirs(download_path, exist_ok=True)\n",
    "    if download_videos:\n",
    "        title_data = download_videos_from_links(video_ids, video_links, download_path)\n",
    "        \n",
    "    # Extract audio from videos\n",
    "    extract_audio_from_mp4(download_path)\n",
    "    audio_files = list_files_by_extensions(download_path, ['wav'])\n",
    "\n",
    "    # transcribe\n",
    "    transcription = []\n",
    "    window = 6  # number of sentences to combine\n",
    "    stride = 3  # number of sentences to 'stride' over, used to create overlap\n",
    "    \n",
    "    for data in tqdm(title_data, desc=\"Processing titles\"):\n",
    "        try:\n",
    "            prediction = pipe(f\"{download_path}/{data[0]}.wav\", batch_size=1, return_timestamps=True)[\"chunks\"]\n",
    "            for i in range(0, len(prediction), stride):\n",
    "                i_end = min(len(prediction)-1, i+window)\n",
    "                text = get_text_from_data(i, i_end, prediction)\n",
    "                transcription.append({\n",
    "                    'start': prediction[i]['timestamp'][0],\n",
    "                    'end': prediction[i_end]['timestamp'][1],\n",
    "                    'text': text,\n",
    "                    'id': str(data[0])+'-'+str(i),\n",
    "                    'url': f\"{data[1]}&t={int(prediction[i]['timestamp'][0])}\",\n",
    "                    \"name\":channel_name,\n",
    "                    \"title\":data[2],\n",
    "                })\n",
    "        except:\n",
    "            print(f\"file not found or processed: {download_path}/{data[0]}.wav\")\n",
    "            \n",
    "    # save to jsonl file\n",
    "    with open(f\"transcription_{channel_name}.jsonl\", 'w') as f:\n",
    "        for record in transcription:\n",
    "            json_str = json.dumps(record)  # Convert dictionary to JSON string\n",
    "            f.write(json_str + '\\n')  # Write the JSON string to file, followed by a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "532a17e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video NhA_WTcMnic has been downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# if the above API fails to identify videos in a channel, manually download them.\n",
    "channel_name = 'vidIQ'\n",
    "download_path = f\"./downloads/{channel_name}\"\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "download_youtube_video('NhA_WTcMnic', path=download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1729e3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The video I0OUsgzq1GY has been downloaded successfully!\n",
      "The video d4NbtcJZVJs has been downloaded successfully!\n",
      "The video 4bxP9xJBRMQ has been downloaded successfully!\n",
      "The video mF_yu5CdE3I has been downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "download_youtube_video('I0OUsgzq1GY', path=download_path)\n",
    "download_youtube_video('d4NbtcJZVJs', path=download_path)\n",
    "download_youtube_video('4bxP9xJBRMQ', path=download_path)\n",
    "download_youtube_video('mF_yu5CdE3I', path=download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af4176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in ./downloads/vidIQ/Small Channels Do THIS To TRIGGER The YouTube Algorithm!.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in ./downloads/vidIQ/How Faceless Channels Make Millions Avoiding Copyright.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in ./downloads/vidIQ/YouTube Launches NEW AI Tools for ALL Creators.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in ./downloads/vidIQ/I Built an AI to Automate My YouTube Work.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "MoviePy - Writing audio in ./downloads/vidIQ/How to Find Your Next Viral Video Idea.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9439089f05244a8c9513a0b1c0f28424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing titles:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract audio from videos\n",
    "extract_audio_from_mp4(download_path)\n",
    "audio_files = list_files_by_extensions(download_path, ['wav'])\n",
    "\n",
    "# transcribe\n",
    "transcription = []\n",
    "window = 6  # number of sentences to combine\n",
    "stride = 3  # number of sentences to 'stride' over, used to create overlap\n",
    "\n",
    "for data in tqdm(audio_files, desc=\"Processing titles\"):\n",
    "    try:\n",
    "        filename = os.path.basename(data)\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        prediction = pipe(data, batch_size=1, return_timestamps=True)[\"chunks\"]\n",
    "        for i in range(0, len(prediction), stride):\n",
    "            i_end = min(len(prediction)-1, i+window)\n",
    "            text = get_text_from_data(i, i_end, prediction)\n",
    "            transcription.append({\n",
    "                'start': prediction[i]['timestamp'][0],\n",
    "                'end': prediction[i_end]['timestamp'][1],\n",
    "                'text': text,\n",
    "                'id': base_name+'-'+str(i),\n",
    "                'url': f\"https://www.youtube.com/watch?v={base_name}&t={int(prediction[i]['timestamp'][0])}\",\n",
    "                \"name\":channel_name,\n",
    "                \"title\":base_name,\n",
    "            })\n",
    "    except:\n",
    "        print(f\"file not found or processed: {download_path}/{data[0]}.wav\")\n",
    "        \n",
    "# save to jsonl file\n",
    "with open(f\"transcription_{channel_name}.jsonl\", 'w') as f:\n",
    "    for record in transcription:\n",
    "        json_str = json.dumps(record)  # Convert dictionary to JSON string\n",
    "        f.write(json_str + '\\n')  # Write the JSON string to file, followed by a new line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76ac7210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./downloads/vidIQ/I Built an AI to Automate My YouTube Work.wav',\n",
       " './downloads/vidIQ/YouTube Launches NEW AI Tools for ALL Creators.wav',\n",
       " './downloads/vidIQ/Small Channels Do THIS To TRIGGER The YouTube Algorithm!.wav',\n",
       " './downloads/vidIQ/How to Find Your Next Viral Video Idea.wav',\n",
       " './downloads/vidIQ/How Faceless Channels Make Millions Avoiding Copyright.wav']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2ecf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b93c232",
   "metadata": {},
   "source": [
    "# Read pdf documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecc10a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_path = './urtec/2023'\n",
    "PDF_filenames = get_files_recursive(document_path)\n",
    "file_data = read_file_data(document_path, PDF_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac99c7a",
   "metadata": {},
   "source": [
    "## Write to Vector DB\n",
    "### Setup connection and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8873ef37",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_environment = 'us-west1-gcp'\n",
    "index_name = 'media'\n",
    "\n",
    "# init connection to pinecone\n",
    "pinecone.init(\n",
    "    api_key=pinecone_api_key,  # app.pinecone.io\n",
    "    environment=pinecone_environment # find next to api key\n",
    ")\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    pinecone.create_index(\n",
    "        index_name,\n",
    "        dim,\n",
    "        metric=\"dotproduct\"\n",
    "    )\n",
    "\n",
    "index = pinecone.GRPCIndex(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af11b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# create sparse model\n",
    "sparse_model_id = 'naver/splade-cocondenser-ensembledistil'\n",
    "\n",
    "sparse_model = Splade(sparse_model_id, agg='max')\n",
    "sparse_model.to(device)  # move to GPU if possible\n",
    "sparse_model.eval()\n",
    "\n",
    "# The model takes tokenized inputs that are built using a tokenizer initialized with the same model ID.\n",
    "tokenizer = AutoTokenizer.from_pretrained(sparse_model_id)\n",
    "\n",
    "\n",
    "# create dense model\n",
    "dense_model = SentenceTransformer(\n",
    "    'msmarco-bert-base-dot-v5',\n",
    "    device=device\n",
    ")\n",
    "\n",
    "# The model returns 768 dimensional dense vectors, this is also reflected in the model attributes.\n",
    "dim = dense_model.get_sentence_embedding_dimension()\n",
    "dim "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b29d91",
   "metadata": {},
   "source": [
    "### write video transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60387d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "for i in tqdm(range(0, len(transcription), batch_size)):\n",
    "    # extract batch of data\n",
    "    i_end = min(i+batch_size, len(transcription))\n",
    "    batch = transcription[i:i_end]\n",
    "    # pass data to builder and upsert\n",
    "    index.upsert(builder(transcription[i:i+batch_size]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e151f76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### write file data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e0863e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "for i in tqdm(range(0, len(file_data), batch_size)):\n",
    "    try:\n",
    "        # extract batch of data\n",
    "        i_end = min(i+batch_size, len(file_data))\n",
    "        batch = file_data[i:i_end]\n",
    "        # pass data to builder and upsert\n",
    "        index.upsert(builder_files(file_data[i:i+batch_size]))\n",
    "    except:\n",
    "        print(\"error with batch: \"+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89d1f94",
   "metadata": {},
   "source": [
    "## Retrieve from vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b512c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text: str):\n",
    "    # create dense vec\n",
    "    dense_vec = dense_model.encode(text).tolist()\n",
    "    # create sparse vec\n",
    "    input_ids = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        sparse_vec = sparse_model(\n",
    "            d_kwargs=input_ids.to(device)\n",
    "        )['d_rep'].squeeze()\n",
    "    # convert to dictionary format\n",
    "    indices = sparse_vec.nonzero().squeeze().cpu().tolist()\n",
    "    values = sparse_vec[indices].cpu().tolist()\n",
    "    sparse_dict = {\"indices\": indices, \"values\": values}\n",
    "    # return vecs\n",
    "    return dense_vec, sparse_dict\n",
    "\n",
    "def hybrid_scale(dense, sparse, alpha: float):\n",
    "    # check alpha value is in range\n",
    "    if alpha < 0 or alpha > 1:\n",
    "        raise ValueError(\"Alpha must be between 0 and 1\")\n",
    "    # scale sparse and dense vectors to create hybrid search vecs\n",
    "    hsparse = {\n",
    "        'indices': sparse['indices'],\n",
    "        'values':  [v * (1 - alpha) for v in sparse['values']]\n",
    "    }\n",
    "    hdense = [v * alpha for v in dense]\n",
    "    return hdense, hsparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f304158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'matches': [{'id': 'IJP2XayQeeo-150',\n",
       "              'metadata': {'channel': 'missedfortune',\n",
       "                           'context': \" I'll show you how you can learn about \"\n",
       "                                      'these and read actual stories. So, here '\n",
       "                                      'we go. When you use the Laser Fund to '\n",
       "                                      'accumulate  your money tax-free and you '\n",
       "                                      'can access it tax-free with an '\n",
       "                                      'electronic funds transfer or phone '\n",
       "                                      'call,  you can use it for real estate '\n",
       "                                      'management. So, see many people who '\n",
       "                                      'invest in real estate,  they will '\n",
       "                                      \"finance their properties and they'll \"\n",
       "                                      \"borrow money or mortgages let's  say at \"\n",
       "                                      \"4.5% deductible interest. So, that's a \"\n",
       "                                      'net cost of 3%.  So, on a '\n",
       "                                      \"million-dollar mortgage, they don't pay \"\n",
       "                                      '45,000 out of their ',\n",
       "                           'title': 'Best Financial Tool | IUL Is Like A '\n",
       "                                    'Financial Swiss Army Knife',\n",
       "                           'url': 'https://www.youtube.com/watch?v=IJP2XayQeeo&t=838'},\n",
       "              'score': 58.697144,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': 'SaOnDMWJthw-9',\n",
       "              'metadata': {'channel': 'missedfortune',\n",
       "                           'context': \" There's a third kind of person. The \"\n",
       "                                      \"ones who understand when it's wise to  \"\n",
       "                                      'pay interest to make more interest like '\n",
       "                                      'banks, credit unions, insurance '\n",
       "                                      'companies  and the like. The bank will '\n",
       "                                      'very gladly pay you 1% interest. On '\n",
       "                                      'every million  dollars of other '\n",
       "                                      \"people's money, they pay 1%. That's \"\n",
       "                                      'only 10,000 a year  they pay. They loan '\n",
       "                                      'that out over and over and over again. '\n",
       "                                      \"Just let's just say on one. One of \"\n",
       "                                      \"those transactions, they're loaning it \"\n",
       "                                      'out at 5. How much ',\n",
       "                           'title': 'Why banks pay you interest',\n",
       "                           'url': 'https://www.youtube.com/watch?v=SaOnDMWJthw&t=24'},\n",
       "              'score': 58.407486,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': 'IJP2XayQeeo-144',\n",
       "              'metadata': {'channel': 'missedfortune',\n",
       "                           'context': ' using the million in his business to '\n",
       "                                      'make money. Do you know in 2017, he '\n",
       "                                      'borrowed a million at 5%  borrowed a '\n",
       "                                      'million at 5% and earned 25% that year. '\n",
       "                                      'So, he made a quarter of a million,  '\n",
       "                                      '50,000 of that paid for that interest '\n",
       "                                      'on the loan and he netted 20% or '\n",
       "                                      '200,000 tax-free on his million in his '\n",
       "                                      'policy while he was using that million '\n",
       "                                      'in his business to make money.  Does '\n",
       "                                      \"that make sense? It's working capital. \"\n",
       "                                      'What are some other  benefits? Watch. '\n",
       "                                      'So, you can use it for all kinds of '\n",
       "                                      \"other financial goals. That's why  I \"\n",
       "                                      'compare it to a financial Swiss army '\n",
       "                                      'knife. What are some of the other uses? '\n",
       "                                      'And then ',\n",
       "                           'title': 'Best Financial Tool | IUL Is Like A '\n",
       "                                    'Financial Swiss Army Knife',\n",
       "                           'url': 'https://www.youtube.com/watch?v=IJP2XayQeeo&t=793'},\n",
       "              'score': 57.91007,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': 'c-b161tzDlo-0',\n",
       "              'metadata': {'channel': 'missedfortune',\n",
       "                           'context': ' How do banks and credit unions make '\n",
       "                                      'money? They borrow our money at 1 or 2 '\n",
       "                                      'percent. So,  every million they borrow '\n",
       "                                      'from us, they pay 10,000 or 20,000 in '\n",
       "                                      'interest. But what do they do with  our '\n",
       "                                      'money? They turn around and invest it '\n",
       "                                      'or loan it back to us at 5 or 6 '\n",
       "                                      \"percent. So, they're  earning 60,000 on \"\n",
       "                                      'that million. Would you hire an '\n",
       "                                      'employee for 20,000 that made you an '\n",
       "                                      'extra 60,000 on that million, would you '\n",
       "                                      'hire an employee for 20,000 that made '\n",
       "                                      'you an  extra 60,000? Any business '\n",
       "                                      'owner knows that. That is a 300% return '\n",
       "                                      'on  employment costs or equipment '\n",
       "                                      'costs. By learning how money works, you '\n",
       "                                      'can become ',\n",
       "                           'title': 'Banks Multiply our Money',\n",
       "                           'url': 'https://www.youtube.com/watch?v=c-b161tzDlo&t=0'},\n",
       "              'score': 57.630188,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': 'FsH1mKK8AGc-54',\n",
       "              'metadata': {'channel': 'missedfortune',\n",
       "                           'context': \" incredible results. Let's use the rule \"\n",
       "                                      'of 72. See, the rule of 72 says that '\n",
       "                                      \"you take  the interest rate that you're \"\n",
       "                                      'earning on any investment and divide  '\n",
       "                                      'that interest rate into the number 72.  '\n",
       "                                      'So, 8% into 72 means your money will '\n",
       "                                      \"double every 9 years.  If you're \"\n",
       "                                      'earning 10%, your money will double '\n",
       "                                      \"every 7.2 years.  If you're earning \"\n",
       "                                      '7.2% which is the average that people '\n",
       "                                      'earned in the worst decade since the '\n",
       "                                      'Great Depression. 2000 to 2010. Just '\n",
       "                                      'falling asleep and waking up 10 years '\n",
       "                                      'later, ',\n",
       "                           'title': \"What's The Minimum Amount You Can Invest \"\n",
       "                                    'In A Tax-Free IUL?',\n",
       "                           'url': 'https://www.youtube.com/watch?v=FsH1mKK8AGc&t=295'},\n",
       "              'score': 57.474724,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': 'IJP2XayQeeo-147',\n",
       "              'metadata': {'channel': 'missedfortune',\n",
       "                           'context': \" Does that make sense? It's working \"\n",
       "                                      'capital. What are some other  benefits? '\n",
       "                                      'Watch. So, you can use it for all kinds '\n",
       "                                      \"of other financial goals. That's why  I \"\n",
       "                                      'compare it to a financial Swiss army '\n",
       "                                      'knife. What are some of the other uses? '\n",
       "                                      \"And then  I'll show you how you can \"\n",
       "                                      'learn about these and read actual '\n",
       "                                      'stories. So, here we go. When you use '\n",
       "                                      'the Laser Fund to accumulate  your '\n",
       "                                      'money tax-free and you can access it '\n",
       "                                      'tax-free with an electronic funds '\n",
       "                                      'transfer or phone call,  you can use it '\n",
       "                                      'for real estate management. So, see '\n",
       "                                      'many people who invest in real estate, ',\n",
       "                           'title': 'Best Financial Tool | IUL Is Like A '\n",
       "                                    'Financial Swiss Army Knife',\n",
       "                           'url': 'https://www.youtube.com/watch?v=IJP2XayQeeo&t=822'},\n",
       "              'score': 57.443275,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': 'IJP2XayQeeo-39',\n",
       "              'metadata': {'channel': 'missedfortune',\n",
       "                           'context': ' investment place where you put money. '\n",
       "                                      'And you can score it on a scale of 1 to '\n",
       "                                      '10  based upon liquidity. The ability '\n",
       "                                      'to access your money when you need it. '\n",
       "                                      '10 being  a perfect score. Safety, 1 to '\n",
       "                                      '10. Rate of return and also tax '\n",
       "                                      'benefits. Do you know that most  places '\n",
       "                                      'where people put money IRAs and 401Ks, '\n",
       "                                      'mutual funds, banks, credit unions, all '\n",
       "                                      'kinds  of places where people put '\n",
       "                                      'money, annuities and what have you, '\n",
       "                                      'they only score maybe 18 to 22 possible '\n",
       "                                      'points out of 40. See, if you got a '\n",
       "                                      'perfect score 10,  10, 10, 10, that '\n",
       "                                      'would be 40. Now, the Laser Fund '\n",
       "                                      \"doesn't score a perfect 40. \",\n",
       "                           'title': 'Best Financial Tool | IUL Is Like A '\n",
       "                                    'Financial Swiss Army Knife',\n",
       "                           'url': 'https://www.youtube.com/watch?v=IJP2XayQeeo&t=214'},\n",
       "              'score': 57.275196,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': 'IJP2XayQeeo-45',\n",
       "              'metadata': {'channel': 'missedfortune',\n",
       "                           'context': ' Nothing does. But it scores higher '\n",
       "                                      'than any other investment by far. '\n",
       "                                      'Generally,  between 33 and 35 points '\n",
       "                                      'out of 40. It blows the others out of '\n",
       "                                      \"the  water. But here's what it can do \"\n",
       "                                      'for you. When you begin to understand '\n",
       "                                      'how to accumulate access and  transfer '\n",
       "                                      'your money tax-free and earn '\n",
       "                                      'predictable rates of return like I have '\n",
       "                                      'for the last 4 and a half decades. '\n",
       "                                      'Averaging 8.2% just using the strategy '\n",
       "                                      'of indexing. But when you rebalance '\n",
       "                                      'which is  explained in the book, you '\n",
       "                                      'can tweak the rates of return up to 9 '\n",
       "                                      'and 10 percent.  You can earn 10 '\n",
       "                                      \"netting 9. What's the 1%? It's not tax \"\n",
       "                                      \"because it's tax-free. \",\n",
       "                           'title': 'Best Financial Tool | IUL Is Like A '\n",
       "                                    'Financial Swiss Army Knife',\n",
       "                           'url': 'https://www.youtube.com/watch?v=IJP2XayQeeo&t=256'},\n",
       "              'score': 57.191963,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': '1uD3Mvx0K60-96',\n",
       "              'metadata': {'channel': 'missedfortune',\n",
       "                           'context': ' People use their insurance for the '\n",
       "                                      'banking concept to buy real estate, to '\n",
       "                                      'use for working  capital for business '\n",
       "                                      \"and so forth.  If you don't understand \"\n",
       "                                      'this concept, watch other episodes '\n",
       "                                      'where I explain how to become your own  '\n",
       "                                      \"banker. So, let's say I have a million \"\n",
       "                                      'dollars of cash value. If it was a '\n",
       "                                      'whole life policy,  I could borrow that '\n",
       "                                      'and they will credit me a little bit '\n",
       "                                      \"higher interest rate and I'm paying  \"\n",
       "                                      'myself interest as I put money back '\n",
       "                                      'into the policy and so forth. Folks, '\n",
       "                                      \"that's okay. Yeah, if you borrow it too \"\n",
       "                                      'and you earn 4, 4% is 100% more than '\n",
       "                                      '2%. I get it. ',\n",
       "                           'title': 'Infinite Banking With IUL Versus Whole '\n",
       "                                    'Life',\n",
       "                           'url': 'https://www.youtube.com/watch?v=1uD3Mvx0K60&t=598'},\n",
       "              'score': 57.144844,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []},\n",
       "             {'id': 'loLzPU8JVSQ-12',\n",
       "              'metadata': {'channel': 'missedfortune',\n",
       "                           'context': ' owner or even a real estate investor.  '\n",
       "                                      \"So, here's how money works.  When you \"\n",
       "                                      'have your money, your working capital '\n",
       "                                      'on hand, a lot of business owners, '\n",
       "                                      \"they're  so busy running their business \"\n",
       "                                      'that they put the money in a bank or a '\n",
       "                                      \"credit union  thinking, well, it's \"\n",
       "                                      \"liquid. It's over here, it's safe. \"\n",
       "                                      \"Well, what's a bank or credit  union \"\n",
       "                                      \"giving you? Like less than 1%. That's \"\n",
       "                                      'not very smart just because you ',\n",
       "                           'title': 'How Savvy Business Owners Use Max Funded '\n",
       "                                    'IUL as a Working Capital Account',\n",
       "                           'url': 'https://www.youtube.com/watch?v=loLzPU8JVSQ&t=68'},\n",
       "              'score': 57.016502,\n",
       "              'sparse_values': {'indices': [], 'values': []},\n",
       "              'values': []}],\n",
       " 'namespace': ''}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do I use others people money to make investments?\"\n",
    "dense, sparse = encode(query)\n",
    "hdense, hsparse = hybrid_scale(dense, sparse, alpha=0.3)\n",
    "# query\n",
    "xc = index.query(\n",
    "    vector=hdense,\n",
    "    sparse_vector=hsparse,\n",
    "    top_k=10,  # how many results to return\n",
    "    include_metadata=True\n",
    ")\n",
    "xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "04f2705d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'll show you how you can learn about these and read actual stories. So, here we go. When you use the Laser Fund to accumulate  your money tax-free and you can access it tax-free with an electronic funds transfer or phone call,  you can use it for real estate management. So, see many people who invest in real estate,  they will finance their properties and they'll borrow money or mortgages let's  say at 4.5% deductible interest. So, that's a net cost of 3%.  So, on a million-dollar mortgage, they don't pay 45,000 out of their \""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xc['matches'][0]['metadata']['context']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bd47ad",
   "metadata": {},
   "source": [
    "## Build conversational interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd426e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5390ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = query\n",
    "\n",
    "# get retrievals\n",
    "dense, sparse = encode(query)\n",
    "hdense, hsparse = hybrid_scale(dense, sparse, alpha=0.3)\n",
    "# query\n",
    "xc = index.query(\n",
    "    vector=hdense,\n",
    "    sparse_vector=hsparse,\n",
    "    top_k=10,  # how many results to return\n",
    "    include_metadata=True\n",
    ")\n",
    "context  = \"\\n\\nContext: \"\n",
    "for retrieval in xc['matches']:\n",
    "    context = context + retrieval['metadata']['context'] + \"\\n\"\n",
    "\n",
    "conversation.append({\"role\": \"user\", \"content\": user_input+context+\"\\nAnswer:\"})\n",
    "response = openai.ChatCompletion.create(\n",
    "      engine=deployment_name, # The deployment name you chose when you deployed the GPT-35-turbo or GPT-4 model.\n",
    "      messages=conversation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11aba8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In order to use other people\\'s money to make investments, you can consider the following strategies:\\n\\n1. Borrowing from banks or credit unions: Consider securing a loan or mortgage to finance your investments, particularly in real estate. This could allow you to take advantage of the low interest rates offered by these financial institutions, while earning a greater return on your investment.\\n\\n2. Using the Laser Fund: The Laser Fund is a tax-free investment vehicle that allows you to accumulate money and access it tax-free for various financial goals, including real estate management. By leveraging the Laser Fund, you could use the funds for investments and potentially earn higher returns.\\n\\n3. Becoming your own banker: Utilize the concept of \"becoming your own banker\" by borrowing against whole life insurance policies that have accumulated cash value. This can provide access to working capital for investments, while also paying yourself interest as you repay the loan.\\n\\n4. Partnering with other investors: Seek out investors who are interested in co-investing in a project or business venture with you. By pooling resources, you can leverage each other\\'s capital and expertise to achieve greater potential returns on your investments.\\n\\n5. Equity financing: If you own a business or have a promising investment idea, you can also seek out equity financing from private investors or venture capitalists. This involves giving up a percentage of ownership in your business in exchange for funding, but it can provide you with the necessary capital for your investments.\\n\\nRemember, always perform thorough research, analysis, and risk assessment before making any investments. Additionally, consult with a financial advisor if you\\'re not experienced in investing or unsure about potential opportunities.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bb9c5d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Finding an investment that offers high returns with low risk is challenging because typically, higher returns come with higher risks. However, one option to consider is the Laser Fund, which is designed to provide tax-free accumulation and access to money with a focus on liquidity, safety, predictable rates of return, and tax benefits.\\n\\nThe Laser Fund scores between 33 and 35 points out of a possible 40, when ranking investments based on liquidity, safety, rate of return, and tax benefits. It provides predictable rates of return, averaging 8.2% using the strategy of indexing, which can be tweaked up to 9-10% when rebalancing.\\n\\nWhile not a perfect investment option, the Laser Fund is considered a safer choice compared to other investments like IRAs, 401(k)s, mutual funds, banks, credit unions, and annuities. It is important to remember that all investments carry some level of risk, and you should always conduct thorough research and consult a financial advisor before making any investment decisions.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# continue conversation\n",
    "conversation.append({\"role\": \"assistant\", \"content\": response[\"choices\"][0][\"message\"][\"content\"]})\n",
    "query = \"what is the best investment for a high return with low risk?\"\n",
    "user_input = query\n",
    "\n",
    "# get retrievals\n",
    "dense, sparse = encode(query)\n",
    "hdense, hsparse = hybrid_scale(dense, sparse, alpha=0.3)\n",
    "# query\n",
    "xc = index.query(\n",
    "    vector=hdense,\n",
    "    sparse_vector=hsparse,\n",
    "    top_k=10,  # how many results to return\n",
    "    include_metadata=True\n",
    ")\n",
    "context  = \"\\n\\ncontext: \"\n",
    "for retrieval in xc['matches']:\n",
    "    context = context + retrieval['metadata']['context'] + \"\\n\"\n",
    "\n",
    "conversation.append({\"role\": \"user\", \"content\": user_input+context+\"\\nAnswer:\"})\n",
    "response = openai.ChatCompletion.create(\n",
    "      engine=deployment_name, # The deployment name you chose when you deployed the GPT-35-turbo or GPT-4 model.\n",
    "      messages=conversation\n",
    ")\n",
    "response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "50405035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To identify and address frac-driven interference events, follow these steps:\\n\\n1. Detect breakpoints in PI decline: Use the MS-PIBF method to automatically detect any breakpoints in productivity index (PI) decline against cumulative fluid produced and identify it as a segment.\\n\\n2. Segment verification: Verify if the PI segmentation is an outcome of a frac-hit event or an offset well production interference. Exclude extraneous effects attributed to parent well workovers, such as artificial lift change or stimulation.\\n\\n3. Data-driven approach: Utilize machine learning (ML) algorithms to predict when a child well frac operation will interact and affect a neighboring parent well. Create an ML training dataset using legacy production data, representing fracture interference events.\\n\\n4. Monitor production trends: Track changes in well productivity, water cut, and pressure spikes in parent wells, which may indicate a frac-hit event.\\n\\n5. Implement prevention and mitigation methods: Apply methods to prevent or reduce the effects of frac hits, such as adjusting well spacing, optimizing fracturing treatments, and identifying possible remediation treatments for affected wells.\\n\\n6. Continuous improvement: Collaborate with subject matter experts (SMEs) to validate the data and improve the ML models for better prediction and management of frac-driven interference events in the future.\\n\\nIn summary, detecting and addressing frac-driven interference events involve a combination of automated segmentation, verification, data-driven ML models, monitoring production trends, and implementing prevention and mitigation methods. Continuous improvement with SMEs' collaboration is necessary to better manage these events.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new conversation\n",
    "conversation=[{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "query = \"How do I identify and address frac driven interference events?\"\n",
    "\n",
    "user_input = query\n",
    "\n",
    "# get retrievals\n",
    "dense, sparse = encode(query)\n",
    "hdense, hsparse = hybrid_scale(dense, sparse, alpha=0.3)\n",
    "# query\n",
    "xc = index.query(\n",
    "    vector=hdense,\n",
    "    sparse_vector=hsparse,\n",
    "    top_k=10,  # how many results to return\n",
    "    include_metadata=True\n",
    ")\n",
    "context  = \"\\n\\ncontext: \"\n",
    "for retrieval in xc['matches']:\n",
    "    context = context + retrieval['metadata']['context'] + \"\\n\"\n",
    "\n",
    "conversation.append({\"role\": \"user\", \"content\": user_input+context+\"\\nAnswer:\"})\n",
    "response = openai.ChatCompletion.create(\n",
    "      engine=deployment_name, # The deployment name you chose when you deployed the GPT-35-turbo or GPT-4 model.\n",
    "      messages=conversation\n",
    ")\n",
    "response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d04dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
