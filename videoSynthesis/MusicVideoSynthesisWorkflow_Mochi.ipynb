{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17f87d72-5305-4778-ba0c-31549333c8db",
   "metadata": {},
   "source": [
    "# Music Video Synthesis\n",
    "* Extract lyrics from song with timestamps\n",
    "* Compose scenes, include timestamps\n",
    "* Generate images for each scene\n",
    "* A human should evalute photos and scenes, creating a curated one with the desired characteristics\n",
    "* Construct video text prompt for each scene\n",
    "* Build videos for each scene, use referall link to sign up: https://www.segmind.com/invite/773118b7-41f4-4154-87f4-49326d973ec3\n",
    "* Stitch together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8b074-e32d-45f2-977f-c923878625e6",
   "metadata": {},
   "source": [
    "# We will use openai whipser for stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b45c210-fd2b-4381-9fd3-c1eb18feefe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --quiet --upgrade pip\n",
    "#!pip3 install torch==2.4 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124\n",
    "#!pip install --quiet --upgrade openai-whisper openai\n",
    "# Ubuntu or Debian\n",
    "#!sudo apt update && sudo apt install ffmpeg\n",
    "#!pip install setuptools-rust\n",
    "#!pip install -U diffusers imageio imageio_ffmpeg opencv-python moviepy transformers huggingface-hub optimum pillow safetensors optimum-quanto accelerate\n",
    "#!pip install --upgrade optimum-quanto torchao --extra-index-url https://download.pytorch.org/whl/cu124 # full options are cpu/cu118/cu121/cu124\n",
    "#!pip install git+https://github.com/xhinker/sd_embed.git@main\n",
    "#!pip install accelerate flash_attention numba -U\n",
    "#!pip install flash_attn --no-build-isolation\n",
    "#!pip install -r requirements.txt -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8537e766-eab2-4757-b6f9-fbac4da44930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-17 00:42:24.496033: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-17 00:42:24.501787: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1731825744.508612    5509 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1731825744.510684    5509 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-17 00:42:24.518372: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import cv2\n",
    "import diffusers\n",
    "import gc\n",
    "import imageio\n",
    "import imageio_ffmpeg\n",
    "import json\n",
    "import math\n",
    "import moviepy.editor as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "import tempfile\n",
    "import time\n",
    "import transformers\n",
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import whisper\n",
    "\n",
    "from contextlib import contextmanager\n",
    "from datetime import datetime, timedelta\n",
    "from diffusers import AutoencoderKL, AutoPipelineForText2Image, MochiPipeline, MochiTransformer3DModel\n",
    "from diffusers.image_processor import VaeImageProcessor\n",
    "from diffusers.pipelines.flux.pipeline_flux import FluxPipeline\n",
    "from diffusers.utils import export_to_video, load_video, load_image\n",
    "from huggingface_hub import hf_hub_download, snapshot_download\n",
    "from model4 import T5EncoderModel as m_T5EncoderModel, FluxTransformer2DModel\n",
    "from numba import cuda\n",
    "from openai import OpenAI\n",
    "from optimum.quanto import freeze, qfloat8, quantize, requantize\n",
    "from PIL import Image\n",
    "from safetensors.torch import load_file as load_safetensors, save_file as save_safetensors\n",
    "from sd_embed.embedding_funcs import get_weighted_text_embeddings_flux1\n",
    "from torchao.quantization import quantize_, int8_weight_only, int8_dynamic_activation_int8_weight\n",
    "from transformers import CLIPTextModel, CLIPTokenizer, T5TokenizerFast, T5EncoderModel as t_T5EncoderModel\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "# Define the paths where quantized weights will be saved\n",
    "\n",
    "dtype = torch.bfloat16\n",
    "MAX_SEED = np.iinfo(np.int32).max\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "retry_limit = 3\n",
    "quantization = int8_weight_only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f54ba32-2208-45c8-8ed2-5fcb1e79aaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"openai_api_key\": \"\",\n",
    "    \"openai_model\": \"gpt-4o-mini\",\n",
    "    \"openai_model_large\": \"gpt-4o\",\n",
    "    \"hf_token\": \"\",\n",
    "    \"base_working_dir\": \"./images\",\n",
    "    \"base_video_dir\": \"./output\",\n",
    "    \"audio_files\": [\n",
    "        \"//mnt/d/audio/AlphabetJoy.mp3\",\n",
    "        \"//mnt/d/audio/AlphabetJoy.mp3\",\n",
    "        \"//mnt/d/audio/AlphabetJoy.mp3\",\n",
    "        \"//mnt/d/audio/AlphabetJoy.mp3\",\n",
    "        \"//mnt/d/audio/AlphabetJoy.mp3\",\n",
    "        # Add more audio file paths here\n",
    "    ],\n",
    "    \"device\": device,\n",
    "    \"dtype\": dtype,\n",
    "    \"retry_limit\": retry_limit,\n",
    "    \"MAX_SEED\": MAX_SEED\n",
    "}\n",
    "\n",
    "# Ensure base directories exist\n",
    "os.makedirs(CONFIG[\"base_working_dir\"], exist_ok=True)\n",
    "os.makedirs(CONFIG[\"base_video_dir\"], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c34281c1-e231-4472-9d9b-096fa23b4e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_memory(device):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    torch.cuda.reset_accumulated_memory_stats(device)\n",
    "    torch.cuda.synchronize()\n",
    "    \n",
    "def get_openai_prompt_response(\n",
    "    prompt: str,\n",
    "    config: dict,\n",
    "    max_tokens: int = 6000,\n",
    "    temperature: float = 0.33,\n",
    "    openai_model: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Sends a prompt to OpenAI's API and retrieves the response with retry logic.\n",
    "    \"\"\"\n",
    "    client = OpenAI(api_key=config[\"openai_api_key\"])\n",
    "    response = client.chat.completions.create(\n",
    "        max_tokens=max_tokens,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"Act as a helpful assistant, you are an expert editor.\"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        model=openai_model or config[\"openai_model\"],\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    retry_count = 0\n",
    "    while retry_count < config[\"retry_limit\"]:\n",
    "        try:\n",
    "            message_content = response.choices[0].message.content\n",
    "            return message_content\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            retry_count += 1\n",
    "            if retry_count == config[\"retry_limit\"]:\n",
    "                print(\"Retry limit reached. Moving to the next iteration.\")\n",
    "                return \"\"\n",
    "            else:\n",
    "                print(f\"Retrying... (Attempt {retry_count}/{config['retry_limit']})\")\n",
    "                time.sleep(1)  # Optional: wait before retrying\n",
    "\n",
    "\n",
    "def load_flux_pipe_4bit():\n",
    "    text_encoder_2 = m_T5EncoderModel.from_pretrained(\n",
    "        \"HighCWu/FLUX.1-dev-4bit\",\n",
    "        subfolder=\"text_encoder_2\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        # hqq_4bit_compute_dtype=torch.float32,\n",
    "    )\n",
    "    \n",
    "    transformer = FluxTransformer2DModel.from_pretrained(\n",
    "        \"HighCWu/FLUX.1-dev-4bit\",\n",
    "        subfolder=\"transformer\",\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    \n",
    "    pipe = FluxPipeline.from_pretrained(\n",
    "        \"black-forest-labs/FLUX.1-dev\",\n",
    "        text_encoder_2=text_encoder_2,\n",
    "        transformer=transformer,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    #pipe.enable_model_cpu_offload() # with cpu offload, it cost 8.5GB vram\n",
    "    pipe.remove_all_hooks()\n",
    "    pipe = pipe.to('cuda') # without cpu offload, it cost 11GB vram\n",
    "\n",
    "    del text_encoder_2\n",
    "    del transformer\n",
    "\n",
    "    return pipe\n",
    "\n",
    "def gen_flux_image(pipe, prompt, config: dict, height=1024, width=1024, guidance_scale=3.5, num_inference_steps=4, max_sequence_length=512, seed=-1):\n",
    "    \"\"\"\n",
    "    Generates an image based on the provided prompt using the Flux pipeline.\n",
    "    \"\"\"\n",
    "    if seed == -1:\n",
    "        seed = random.randint(0, MAX_SEED)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        prompt_embeds, pooled_prompt_embeds = get_weighted_text_embeddings_flux1(\n",
    "            pipe        = pipe,\n",
    "            prompt    = prompt\n",
    "        )\n",
    "        \n",
    "        image = pipe(\n",
    "            prompt_embeds               = prompt_embeds,\n",
    "            pooled_prompt_embeds      = pooled_prompt_embeds,\n",
    "            height=height,\n",
    "            width=width,\n",
    "            guidance_scale=guidance_scale,\n",
    "            output_type=\"pil\",\n",
    "            num_inference_steps=num_inference_steps,\n",
    "            max_sequence_length=max_sequence_length,\n",
    "            generator=torch.Generator(\"cpu\").manual_seed(seed)\n",
    "        ).images[0]\n",
    "\n",
    "        # Delete variables\n",
    "        del prompt_embeds\n",
    "        del pooled_prompt_embeds\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "def image_file_to_base64(image_path):\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_data = f.read()\n",
    "    return base64.b64encode(image_data).decode('utf-8')\n",
    "\n",
    "# Use this function to fetch an image from a URL and convert it to base64\n",
    "def image_url_to_base64(image_url):\n",
    "    response = requests.get(image_url)\n",
    "    image_data = response.content\n",
    "    return base64.b64encode(image_data).decode('utf-8')\n",
    "\n",
    "def load_mochi_pipeline():\n",
    "    # Quantized models do not exist, proceed to load initial pipeline and quantize\n",
    "    print(\"Loading initial pipeline\")\n",
    "    pipe = MochiPipeline.from_pretrained(\"genmo/mochi-1-preview\", variant=\"bf16\", torch_dtype=torch.bfloat16)\n",
    "\n",
    "    print(\"Quantizing VAE\")\n",
    "    vae = pipe.vae\n",
    "    quantize_(vae, quantization())\n",
    "\n",
    "    print(\"Quantizing text encoder\")\n",
    "    text_encoder = pipe.text_encoder\n",
    "    quantize_(text_encoder, quantization())\n",
    "\n",
    "    print(\"Quantizing transformer\")\n",
    "    transformer = pipe.transformer\n",
    "    quantize_(transformer, quantization())\n",
    "\n",
    "    del pipe\n",
    "    reset_memory(device)\n",
    "\n",
    "    print(\"Loading quantized pipeline\")\n",
    "    pipe = MochiPipeline.from_pretrained(\n",
    "        \"genmo/mochi-1-preview\",\n",
    "        variant=\"bf16\",\n",
    "        text_encoder=text_encoder,\n",
    "        transformer=transformer,\n",
    "        vae=vae,\n",
    "        torch_dtype=torch.bfloat16\n",
    "    ).to(device)\n",
    "\n",
    "    return pipe\n",
    "    \n",
    "def generate_video(video_pipe, prompt, frames, video_filename: str = \"\"):\n",
    "    negative_prompt = \"sudden movements, fast zooms.\"\n",
    "    frames = pipe(prompt, negative_prompt=negative_prompt, num_frames=120).frames[0]\n",
    "\n",
    "    export_to_video(frames, video_filename, fps=24)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "def save_video(frames, fps: int, filename: str):\n",
    "    \"\"\"\n",
    "    Saves a list of frames as a video file.\n",
    "    \"\"\"\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n",
    "        temp_video_path = temp_file.name\n",
    "        writer = imageio.get_writer(temp_video_path, fps=fps)\n",
    "        for frame in frames:\n",
    "            writer.append_data(np.array(frame))\n",
    "        writer.close()\n",
    "\n",
    "    os.rename(temp_video_path, filename)\n",
    "    return filename\n",
    "\n",
    "\n",
    "def convert_to_gif(video_path: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts a video file to a GIF.\n",
    "    \"\"\"\n",
    "    clip = mp.VideoFileClip(video_path)\n",
    "    clip = clip.set_fps(8)\n",
    "    clip = clip.resize(height=240)\n",
    "    gif_path = video_path.replace(\".mp4\", \".gif\")\n",
    "    clip.write_gif(gif_path, fps=8)\n",
    "    return gif_path\n",
    "\n",
    "\n",
    "def resize_if_unfit(input_video: str) -> str:\n",
    "    \"\"\"\n",
    "    Resizes the video to the target dimensions if it does not match.\n",
    "    \"\"\"\n",
    "    width, height = get_video_dimensions(input_video)\n",
    "\n",
    "    if width == 720 and height == 480:\n",
    "        return input_video\n",
    "    else:\n",
    "        return center_crop_resize(input_video)\n",
    "\n",
    "\n",
    "def get_video_dimensions(input_video_path: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Retrieves the dimensions of the video.\n",
    "    \"\"\"\n",
    "    reader = imageio_ffmpeg.read_frames(input_video_path)\n",
    "    metadata = next(reader)\n",
    "    return metadata[\"size\"]\n",
    "\n",
    "\n",
    "def center_crop_resize(input_video_path: str, target_width: int = 720, target_height: int = 480) -> str:\n",
    "    \"\"\"\n",
    "    Resizes and center-crops the video to the target dimensions.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "    orig_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    orig_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    orig_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    width_factor = target_width / orig_width\n",
    "    height_factor = target_height / orig_height\n",
    "    resize_factor = max(width_factor, height_factor)\n",
    "\n",
    "    inter_width = int(orig_width * resize_factor)\n",
    "    inter_height = int(orig_height * resize_factor)\n",
    "\n",
    "    target_fps = 8\n",
    "    ideal_skip = max(0, math.ceil(orig_fps / target_fps) - 1)\n",
    "    skip = min(5, ideal_skip)  # Cap at 5\n",
    "\n",
    "    while (total_frames / (skip + 1)) < 49 and skip > 0:\n",
    "        skip -= 1\n",
    "\n",
    "    processed_frames = []\n",
    "    frame_count = 0\n",
    "    total_read = 0\n",
    "\n",
    "    while frame_count < 49 and total_read < total_frames:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if total_read % (skip + 1) == 0:\n",
    "            resized = cv2.resize(frame, (inter_width, inter_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            start_x = (inter_width - target_width) // 2\n",
    "            start_y = (inter_height - target_height) // 2\n",
    "            cropped = resized[start_y:start_y + target_height, start_x:start_x + target_width]\n",
    "\n",
    "            processed_frames.append(cropped)\n",
    "            frame_count += 1\n",
    "\n",
    "        total_read += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".mp4\", delete=False) as temp_file:\n",
    "        temp_video_path = temp_file.name\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "        out = cv2.VideoWriter(temp_video_path, fourcc, target_fps, (target_width, target_height))\n",
    "\n",
    "        for frame in processed_frames:\n",
    "            out.write(frame)\n",
    "\n",
    "        out.release()\n",
    "\n",
    "    return temp_video_path\n",
    "\n",
    "\n",
    "def extract_last_frame(video_filename: str, output_image_filename: str):\n",
    "    \"\"\"\n",
    "    Extracts the last frame from a video file and saves it as an image.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reader = imageio.get_reader(video_filename, 'ffmpeg')\n",
    "        last_frame = None\n",
    "        for frame in reader:\n",
    "            last_frame = frame\n",
    "        reader.close()\n",
    "\n",
    "        if last_frame is not None:\n",
    "            imageio.imwrite(output_image_filename, last_frame)\n",
    "            print(f\"Last frame saved successfully as '{output_image_filename}'.\")\n",
    "        else:\n",
    "            print(\"The video contains no frames.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file '{video_filename}' was not found.\")\n",
    "    except ValueError as ve:\n",
    "        print(f\"ValueError: {ve}\")\n",
    "    except RuntimeError as re:\n",
    "        print(f\"RuntimeError: {re}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "\n",
    "\n",
    "def create_scenes(text: str, video_summary: str, config: dict):\n",
    "    \"\"\"\n",
    "    Creates scenes based on the extracted lyrics using OpenAI's API.\n",
    "    \"\"\"\n",
    "    # Generate scenes JSON\n",
    "    prompt = f'''Create a json list of diverse, unique scenes (groupings of text), scene_description (200 words or less), and action_sequence (30 words or less) from the following text.  Scenes should be groups of lyrics with new scenes when the lyric context changes.  Text: {text}   \n",
    "The json list should have the start value for the first item in the scene and the text that is combined for all items in the same scene.  \n",
    "The scene_description should include details such as attire, setting, mood, lighting, and any significant movements or expressions, painting a clear visual scene consistent with the video theme and different from other scenes.\n",
    "The action_sequence should describe the action in the scene.  Scenes should be unique, creative, imaginative, and awe-inspiring to create an amazing video.  Create beautiful and mesmerizing scene descriptions that are creative, unique, artistic, and imaginative. Each scene must be unique, imaginative, and visually captivating, blending creativity with artistic flair. Use powerful, descriptive language to craft scenes that are awe-inspiring and leave the audience in wonder. These scenes should evoke a sense of beauty, grandeur, mystery, or anything emotional, drawing from both realistic and fantastical elements. Ensure the descriptions are immersive, emotionally resonant, and filled with unexpected twists that engage the senses and imagination, suitable for creating a stunning, cinematic video experience.  Use descriptions of special effects in the scenes.\n",
    "Return only the json list, less jargon. The json list fields should be: start, text, scene_description, action_sequence'''\n",
    "\n",
    "    result = get_openai_prompt_response(prompt, config, openai_model=config[\"openai_model\"], temperature=0.66)\n",
    "    result = result.replace(\"```\", \"\").replace(\"```json\\n\", \"\").replace(\"json\\n\", \"\").replace(\"\\n\", \"\")\n",
    "    scenes = json.loads(result)\n",
    "    return scenes\n",
    "\n",
    "def revise_scenes(scenes, config: dict):\n",
    "    \"\"\"\n",
    "    Revise scenes based on the extracted scenes.\n",
    "    \"\"\"\n",
    "    # Generate scenes JSON\n",
    "    prompt = f'''Revise the JSON scenes to update the scene_description and action_sequence to engage the senses and imagination, suitable for creating a stunning, cinematic video experience.  Use descriptions of special effects in the scenes.  JSON scenes: {scenes}   \n",
    "The scene_description (200 words or less) should include details such as attire, setting, mood, lighting, and any significant movements or expressions, painting a clear visual scene consistent with the video theme and different from other scenes.\n",
    "The action_sequence (30 words or less) should describe the action in the scene.  The goal is to create input to create a stunning, cinematic video experience.\n",
    "Only update the scene_description and action_sequence.  Do not delete any items as having scenes with the given start times are important.  We do not want to have the same scene_description and action_sequence for the items with repeatitive input text.  Please change these to be creative and consistent with dynamic video sequences.\n",
    "Return only the json list, less jargon. The json list fields should be: start, text, scene_description, action_sequence'''\n",
    "\n",
    "    result = get_openai_prompt_response(prompt, config, openai_model=config[\"openai_model\"], temperature=0.33)\n",
    "    result = result.replace(\"```\", \"\").replace(\"```json\\n\", \"\").replace(\"json\\n\", \"\").replace(\"\\n\", \"\")\n",
    "    scenes = json.loads(result)\n",
    "    return scenes\n",
    "\n",
    "\n",
    "def process_audio_scenes(audio_file: str, config: dict):\n",
    "    # set maximum duration for an image basis, should be in intervals of video generation length\n",
    "    video_gen_length = 5\n",
    "    max_duration_seconds  = video_gen_length * 1\n",
    "    \"\"\"\n",
    "    Processes a single audio file through the entire workflow.\n",
    "    \"\"\"\n",
    "    # Create unique identifier based on audio file name\n",
    "    audio_basename = os.path.splitext(os.path.basename(audio_file))[0]\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    unique_id = f\"{audio_basename}_{timestamp}\"\n",
    "\n",
    "    # Create unique directories for images and videos\n",
    "    print(f\"Create unique directories for images and videos\")\n",
    "    audio_images_dir = os.path.join(config[\"base_working_dir\"], unique_id)\n",
    "    audio_videos_dir = os.path.join(config[\"base_video_dir\"], unique_id)\n",
    "    os.makedirs(audio_images_dir, exist_ok=True)\n",
    "    os.makedirs(audio_videos_dir, exist_ok=True)\n",
    "\n",
    "    # Step 1: Transcribe audio using Whisper\n",
    "    print(f\"Transcribe audio using Whisper\")\n",
    "    model = whisper.load_model(\"turbo\")\n",
    "    result = model.transcribe(audio_file)\n",
    "\n",
    "    # Cleanup Whisper model memory\n",
    "    del model\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    segments = result['segments']\n",
    "\n",
    "    # Extract list of start times and texts\n",
    "    segment_texts_and_start_times = [(segment['text'].strip(), segment['start']) for segment in segments]\n",
    "\n",
    "    # Combine texts\n",
    "    text = \"\"\n",
    "    for segment_text, start in segment_texts_and_start_times:\n",
    "        text += f\"Start: {start}, Text: {segment_text}\\n\"\n",
    "\n",
    "    last_end_value = segments[-1]['end']\n",
    "\n",
    "    # Path to scenes.json file\n",
    "    scenes_file_path = os.path.join(audio_images_dir, \"scenes.json\")\n",
    "\n",
    "    # Check if scenes.json exists\n",
    "    if os.path.exists(scenes_file_path):\n",
    "        print(f\"Scenes file already exists at {scenes_file_path}. Skipping scene generation.\")\n",
    "        with open(scenes_file_path, \"r\") as scenes_file:\n",
    "            scenes = json.load(scenes_file)\n",
    "        return scenes, audio_images_dir, audio_videos_dir, last_end_value\n",
    "\n",
    "    # Step 2: Generate video summary using OpenAI\n",
    "    print(f\"Generate video summary using OpenAI\")\n",
    "    video_summary_prompt = f'Create a short summary that describes a music video based on these lyrics: {text}'\n",
    "    video_summary = get_openai_prompt_response(video_summary_prompt, config, openai_model=config[\"openai_model\"])\n",
    "\n",
    "    # Step 3: Create scenes based on lyrics\n",
    "    print(f\"Create scenes based on lyrics\")\n",
    "    try:\n",
    "        scenes = create_scenes(text, video_summary, config)\n",
    "    except:\n",
    "        try:\n",
    "            scenes = create_scenes(text, video_summary, config)\n",
    "        except:\n",
    "            try:\n",
    "                scenes = create_scenes(text, video_summary, config)\n",
    "            except: \n",
    "                return \"\", audio_images_dir, audio_videos_dir, last_end_value\n",
    "            \n",
    "    # we don't want scenes longer than 5 seconds\n",
    "    new_scenes = []\n",
    "    for i in range(len(scenes)):\n",
    "        scene = scenes[i]\n",
    "        if i == 0:\n",
    "            start_time = 0\n",
    "        else:\n",
    "            start_time = scene['start']\n",
    "        # Determine the end time\n",
    "        if i < len(scenes) - 1:\n",
    "            end_time = scenes[i + 1]['start']\n",
    "        else:\n",
    "            end_time = last_end_value\n",
    "        duration = end_time - start_time\n",
    "        # Split the scene if duration exceeds 18 seconds\n",
    "        while duration > 5:\n",
    "            new_scene = scene.copy()\n",
    "            new_scene['start'] = start_time\n",
    "            new_scenes.append(new_scene)\n",
    "            start_time += max_duration_seconds\n",
    "            duration = end_time - start_time\n",
    "        # Append the remaining part of the scene\n",
    "        if duration > 0:\n",
    "            new_scene = scene.copy()\n",
    "            new_scene['start'] = start_time\n",
    "            new_scenes.append(new_scene)\n",
    "    # Replace the original scenes with the new list\n",
    "    scenes = new_scenes\n",
    "    # improve the scenes with a revision\n",
    "    try:\n",
    "        scenes_revised = revise_scenes(scenes, config)\n",
    "        scenes = scenes_revised\n",
    "        print(f'revised scenes')\n",
    "    except:\n",
    "        try:\n",
    "            scenes_revised = revise_scenes(scenes, config)\n",
    "            scenes = scenes_revised\n",
    "            print(f'revised scenes')\n",
    "        except:\n",
    "            print('cannot revise scenes')\n",
    "            \n",
    "    \n",
    "    # Save the scenes to scenes.json\n",
    "    with open(scenes_file_path, \"w\") as scenes_file:\n",
    "        json.dump(scenes, scenes_file)\n",
    "        \n",
    "    return scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp\n",
    "\n",
    "def process_audio_video(config: dict, scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp):\n",
    "    video_pipe = load_mochi_pipeline()\n",
    "    video_num = 1\n",
    "    # Step 7: Generate video sequences\n",
    "    for i, scene in enumerate(scenes):\n",
    "        prompt = scene[\"action_sequence\"]\n",
    "\n",
    "        # Calculate duration to keep the video in 5-second increments\n",
    "        if i + 1 < len(scenes):\n",
    "            next_start_time = scenes[i + 1][\"start\"]\n",
    "        else:\n",
    "            next_start_time = last_end_value  # Use the final ending time for the last scene\n",
    "\n",
    "        if i == 0:\n",
    "            duration = next_start_time\n",
    "        else:\n",
    "            duration = next_start_time - scene[\"start\"]\n",
    "            \n",
    "        num_video_segments = int((duration + 2) // 5)\n",
    "\n",
    "        print(f\"Scene {i+1} has {num_video_segments} segments\")\n",
    "        for j in range(num_video_segments):\n",
    "            video_name = f\"video_{str(video_num).zfill(2)}_{str(i+1)}_{str(j+1).zfill(2)}_{timestamp}.mp4\"\n",
    "            video_output_path = os.path.join(audio_videos_dir, video_name)\n",
    "\n",
    "            generate_video(video_pipe, prompt, image_input, video_filename=video_output_path)\n",
    "            video_num += 1  # Increment video number for the next segment\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def process_all_audios(audio_file, config: dict):\n",
    "    \"\"\"\n",
    "    Processes a list of audio files through the workflow.\n",
    "    \"\"\"\n",
    "    print(f\"Processing audio file: {audio_file}\")\n",
    "    scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp = process_audio_scenes(audio_file, config)\n",
    "    print(f'{len(scenes)} scenes: {scenes}')\n",
    "    return config, scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp\n",
    "\n",
    "def create_video():\n",
    "    config, scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp = process_all_audios(audio_file, CONFIG)\n",
    "    process_audio_video(config, scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp)\n",
    "    print(f'audio_images_dir: {audio_images_dir}')\n",
    "    print(f'audio_videos_dir: {audio_videos_dir}')\n",
    "    print(f'last_end_value: {last_end_value}')\n",
    "    print(f'timestamp: {timestamp}')\n",
    "    reset_memory(device)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04a0cc96-e609-4cd2-9c67-dcd63562988a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing audio file: //mnt/d/audio/AlphabetJoy.mp3\n",
      "Create unique directories for images and videos\n",
      "Transcribe audio using Whisper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:py.warnings:/home/hulk/miniconda3/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate video summary using OpenAI\n",
      "Create scenes based on lyrics\n",
      "revised scenes\n",
      "43 scenes: [{'start': 0, 'text': 'A is for the adventure each day can hold B is for the beauty that unfolds C is for the courage to break the mold D is for the dreams that are bold', 'scene_description': 'In a lush, sun-drenched forest, children in vibrant, whimsical costumes representing letters dance among a kaleidoscope of wildflowers. Sunlight streams through the canopy, casting playful shadows. Their laughter mingles with the gentle rustle of leaves, while colorful butterflies flutter around, creating a scene of pure joy and wonder.', 'action_sequence': 'Children leap and spin, chasing butterflies, their laughter ringing out as they sing and twirl in a joyful celebration of nature.'}, {'start': 5, 'text': 'A is for the adventure each day can hold B is for the beauty that unfolds C is for the courage to break the mold D is for the dreams that are bold', 'scene_description': 'In a vibrant meadow bursting with color, children adorned in playful costumes representing letters run freely. The sun filters through the trees, creating a magical glow. Their joyous laughter fills the air, while butterflies dance around them, embodying the spirit of adventure and beauty.', 'action_sequence': 'Children frolic and twirl, chasing butterflies, their voices harmonizing in a melody of happiness.'}, {'start': 10, 'text': 'A is for the adventure each day can hold B is for the beauty that unfolds C is for the courage to break the mold D is for the dreams that are bold', 'scene_description': 'In a radiant forest, children in colorful costumes representing letters playfully explore. Sunlight filters through the leaves, creating a dreamlike ambiance. Their laughter echoes, and butterflies flit by, enhancing the enchanting atmosphere filled with adventure.', 'action_sequence': 'Children dance and spin, joyfully chasing butterflies, their laughter blending with the melody of nature.'}, {'start': 15, 'text': 'A is for the adventure each day can hold B is for the beauty that unfolds C is for the courage to break the mold D is for the dreams that are bold', 'scene_description': 'In a picturesque forest, children dressed in vibrant costumes run joyfully among blooming flowers. Sunlight filters through the leaves, casting a warm glow. Their laughter echoes, and butterflies flutter around, embodying the essence of adventure and beauty.', 'action_sequence': 'Children leap and twirl, chasing butterflies, their joyful singing resonating through the forest.'}, {'start': 20, 'text': 'A is for the adventure each day can hold B is for the beauty that unfolds C is for the courage to break the mold D is for the dreams that are bold', 'scene_description': 'In a lively forest, children in colorful outfits representing letters dance among a sea of flowers. Sunlight dapples the ground, creating a magical atmosphere. Their laughter harmonizes with the gentle rustling of leaves, while butterflies flit gracefully around them.', 'action_sequence': 'Children whirl and chase butterflies, their laughter ringing out as they sing joyfully.'}, {'start': 25, 'text': 'A is for the adventure each day can hold B is for the beauty that unfolds C is for the courage to break the mold D is for the dreams that are bold', 'scene_description': 'In a vibrant forest, children dressed in colorful letter-themed costumes run joyfully through a field of wildflowers. Sunlight filters through the trees, casting a warm glow. Their laughter echoes, and butterflies dance around them, creating a scene of pure enchantment.', 'action_sequence': 'Children leap and spin, joyfully chasing butterflies, their voices blending in a cheerful song.'}, {'start': 30, 'text': 'A is for the adventure each day can hold B is for the beauty that unfolds C is for the courage to break the mold D is for the dreams that are bold', 'scene_description': 'In a magical forest, children in vibrant costumes representing letters run freely among blooming flowers. Sunlight filters through the leaves, creating a warm, inviting glow. Their laughter fills the air, and butterflies dance around them, embodying the spirit of adventure.', 'action_sequence': 'Children twirl and chase butterflies, their joyous laughter echoing through the trees.'}, {'start': 31.94, 'text': \"E is for the energy that rises with the sun F is for the friendship and fun G is for the growth in everyone H is for the happiness that's never done\", 'scene_description': 'On a sunlit beach at dawn, friends gather, their silhouettes glowing in the golden light. Dressed in colorful beach attire, they splash in the waves, laughter mingling with the sound of seagulls. The salty breeze carries a sense of joy and camaraderie as they embrace the day.', 'action_sequence': 'Friends leap into the surf, splashing each other while laughter fills the air.'}, {'start': 36.94, 'text': \"E is for the energy that rises with the sun F is for the friendship and fun G is for the growth in everyone H is for the happiness that's never done\", 'scene_description': 'As the sun rises over a tranquil beach, friends gather, their silhouettes illuminated by the golden light. Clad in vibrant swimwear, they joyfully splash in the waves, while seagulls soar overhead. The air is filled with laughter and the refreshing scent of the ocean.', 'action_sequence': 'Friends jump into the waves, splashing and laughing, celebrating their bond.'}, {'start': 41.94, 'text': \"E is for the energy that rises with the sun F is for the friendship and fun G is for the growth in everyone H is for the happiness that's never done\", 'scene_description': 'At sunrise on a sun-kissed beach, friends gather, their silhouettes glowing in the warm light. Dressed in bright beachwear, they splash joyfully in the waves, with seagulls calling above. The atmosphere is filled with laughter and the invigorating scent of saltwater.', 'action_sequence': 'Friends leap into the surf, splashing each other while sharing joyous laughter.'}, {'start': 46.94, 'text': \"E is for the energy that rises with the sun F is for the friendship and fun G is for the growth in everyone H is for the happiness that's never done\", 'scene_description': 'On a serene beach at dawn, friends gather, their silhouettes illuminated by the rising sun. Wearing bright beach attire, they splash playfully in the waves, with seagulls soaring overhead. The air is filled with laughter and the refreshing scent of the ocean breeze.', 'action_sequence': 'Friends jump into the waves, splashing and laughing as they celebrate their friendship.'}, {'start': 49.44, 'text': 'This alphabet of joy is my guiding light The love within me shines so bright I sing these letters with all my might A symphony of joy, a delightful flight', 'scene_description': 'In a tranquil meadow under a twilight sky, a solo performer in a flowing gown sings with passion. Fireflies twinkle around her, their soft glow creating a magical ambiance. Lanterns flicker warmly, and the sweet scent of wildflowers fills the air, enhancing the serene atmosphere.', 'action_sequence': 'The singer raises her arms, inviting fireflies closer as she sways gracefully to her melody.'}, {'start': 54.44, 'text': 'This alphabet of joy is my guiding light The love within me shines so bright I sing these letters with all my might A symphony of joy, a delightful flight', 'scene_description': 'In a peaceful meadow at twilight, a solo performer in a flowing gown sings with heartfelt emotion. Fireflies dance around her, their gentle glow illuminating the scene. Soft lanterns cast a warm light, while the fragrant wildflowers add to the enchanting atmosphere.', 'action_sequence': 'The singer lifts her arms, inviting fireflies to dance closer as she sways to her song.'}, {'start': 59.44, 'text': 'This alphabet of joy is my guiding light The love within me shines so bright I sing these letters with all my might A symphony of joy, a delightful flight', 'scene_description': 'In a serene meadow beneath a twilight sky, a solo artist in a flowing gown sings passionately. Fireflies twinkle around her, creating a whimsical glow. Soft lanterns illuminate the scene, and the air is filled with the sweet scent of blooming wildflowers.', 'action_sequence': 'The singer raises her arms, inviting the fireflies closer as she sways to her enchanting melody.'}, {'start': 64.44, 'text': 'This alphabet of joy is my guiding light The love within me shines so bright I sing these letters with all my might A symphony of joy, a delightful flight', 'scene_description': 'In a tranquil meadow under a starry sky, a solo performer in a flowing gown sings with passion. Fireflies dance around her, their flickering lights creating a magical atmosphere. Lanterns glow softly, and the air is filled with the sweet fragrance of wildflowers.', 'action_sequence': 'The singer lifts her arms, inviting fireflies to join her as she sways to her heartfelt song.'}, {'start': 66.88, 'text': 'I is for the inspiration in the air J is for the joy that we share K is for the kindness everywhere L is for the love that we dare', 'scene_description': 'In a vibrant art studio, diverse artists of all ages passionately create colorful murals. The walls burst with paint, and sunlight streams through large windows, illuminating their joyful expressions. The atmosphere buzzes with creativity and collaboration, filled with laughter and inspiration.', 'action_sequence': 'Artists exchange brushes and ideas, collaborating enthusiastically on a massive mural that radiates love and joy.'}, {'start': 71.88, 'text': 'I is for the inspiration in the air J is for the joy that we share K is for the kindness everywhere L is for the love that we dare', 'scene_description': 'In a lively art studio, artists of all ages joyfully create vibrant murals. The walls are alive with color, and sunlight pours in through large windows, illuminating their faces filled with passion. The air is filled with laughter and the spirit of creativity as they share ideas.', 'action_sequence': 'Artists pass brushes and paint, collaborating on a massive mural that celebrates love and joy.'}, {'start': 76.88, 'text': 'I is for the inspiration in the air J is for the joy that we share K is for the kindness everywhere L is for the love that we dare', 'scene_description': 'In a colorful art studio, diverse artists of all ages enthusiastically create vibrant murals. The walls are splashed with paint, and sunlight streams in, illuminating their joyful faces. The atmosphere is alive with creativity, laughter, and the warmth of shared inspiration.', 'action_sequence': 'Artists collaborate, exchanging brushes and ideas, painting a massive mural filled with joy and love.'}, {'start': 81.88, 'text': 'I is for the inspiration in the air J is for the joy that we share K is for the kindness everywhere L is for the love that we dare', 'scene_description': 'In a bustling art studio, artists of various ages joyfully create colorful murals. The walls are vibrant with splashes of paint, and sunlight floods in through large windows, illuminating their enthusiastic expressions. The air buzzes with creativity and laughter, fostering a sense of community.', 'action_sequence': 'Artists exchange brushes and ideas, collaborating on a large mural that radiates joy and kindness.'}, {'start': 86.88, 'text': 'I is for the inspiration in the air J is for the joy that we share K is for the kindness everywhere L is for the love that we dare', 'scene_description': 'In a lively art studio, artists of all ages create vibrant murals with enthusiasm. The walls are a riot of color, and sunlight streams through large windows, highlighting their joyful faces. The atmosphere is filled with laughter and the spirit of collaboration and kindness.', 'action_sequence': 'Artists share brushes and ideas, working together on a massive mural that embodies love and joy.'}, {'start': 91.34, 'text': 'M is for the moments that take our breath away N is for the new things we try each day O is for the opportunities along the way P is for the promise of a new play', 'scene_description': \"At a breathtaking mountain vista during sunset, adventurers gather to witness nature's grandeur. Clad in hiking gear, they gaze in awe at the vibrant sky painted with hues of orange and pink. The crisp wind carries a sense of adventure, and the air is filled with excitement.\", 'action_sequence': 'The group cheers, capturing the stunning sunset with their cameras, celebrating the beauty of the moment.'}, {'start': 96.34, 'text': 'M is for the moments that take our breath away N is for the new things we try each day O is for the opportunities along the way P is for the promise of a new play', 'scene_description': 'On a majestic mountain at sunset, adventurers gather to marvel at the breathtaking view. Dressed in hiking attire, they stand in awe of the vibrant sky, painted with shades of orange and pink. The crisp air is filled with anticipation and wonder, as the wind whispers possibilities.', 'action_sequence': 'The group cheers, capturing the stunning sunset with their cameras, celebrating the beauty of the moment.'}, {'start': 101.34, 'text': 'M is for the moments that take our breath away N is for the new things we try each day O is for the opportunities along the way P is for the promise of a new play', 'scene_description': 'At a breathtaking mountain vista, adventurers gather at sunset, their faces illuminated by the vibrant sky. Clad in hiking gear, they gaze in awe at the stunning colors of orange and pink. The crisp wind carries a sense of adventure and possibility, filling the air with excitement.', 'action_sequence': 'The group cheers, capturing the moment with cameras as the sun dips below the horizon.'}, {'start': 106.34, 'text': 'M is for the moments that take our breath away N is for the new things we try each day O is for the opportunities along the way P is for the promise of a new play', 'scene_description': 'In a stunning mountain landscape at sunset, adventurers gather to take in the breathtaking view. Dressed in hiking attire, they stand in awe of the vibrant sky, painted in hues of orange and pink. The crisp air carries a sense of adventure, filling the atmosphere with excitement.', 'action_sequence': 'The group cheers, capturing the moment with their cameras as the sun sets on the horizon.'}, {'start': 111.34, 'text': 'M is for the moments that take our breath away N is for the new things we try each day O is for the opportunities along the way P is for the promise of a new play', 'scene_description': \"At a breathtaking mountain vista during sunset, adventurers gather to witness nature's beauty. Clad in hiking gear, they gaze in awe at the vibrant sky painted with hues of orange and pink. The wind carries a sense of possibility, and the air is crisp and refreshing.\", 'action_sequence': 'The group cheers, capturing the stunning sunset with their cameras, celebrating the beauty of the moment.'}, {'start': 116.34, 'text': 'M is for the moments that take our breath away N is for the new things we try each day O is for the opportunities along the way P is for the promise of a new play', 'scene_description': 'In a stunning mountain landscape at sunset, adventurers gather to take in the breathtaking view. Dressed in hiking attire, they stand in awe of the vibrant sky, painted in hues of orange and pink. The crisp air carries a sense of adventure, filling the atmosphere with excitement.', 'action_sequence': 'The group cheers, capturing the moment with their cameras as the sun sets on the horizon.'}, {'start': 121.34, 'text': 'M is for the moments that take our breath away N is for the new things we try each day O is for the opportunities along the way P is for the promise of a new play', 'scene_description': \"At a breathtaking mountain vista during sunset, adventurers gather to witness nature's beauty. Clad in hiking gear, they gaze in awe at the vibrant sky painted with hues of orange and pink. The wind carries a sense of possibility, and the air is crisp and refreshing.\", 'action_sequence': 'The group cheers, capturing the stunning sunset with their cameras, celebrating the beauty of the moment.'}, {'start': 125.44000000000001, 'text': 'Q is for the quest that we pursue R is for the rewards that are due S is for the smiles that break through T is for the triumphs in view', 'scene_description': 'In a mystical forest, adventurers clad in deep green and brown cloaks embark on a quest. The atmosphere is thick with mystery as beams of sunlight pierce through the canopy, illuminating their eager expressions. The air is filled with the sounds of rustling leaves and distant birdsong.', 'action_sequence': 'The adventurers stride forward, eyes sparkling with excitement as they uncover hidden treasures in the woods.'}, {'start': 130.44, 'text': 'Q is for the quest that we pursue R is for the rewards that are due S is for the smiles that break through T is for the triumphs in view', 'scene_description': 'In a magical forest, a group of adventurers dressed in cloaks of green and brown set off on a quest. Sunlight filters through the leaves, creating a mystical ambiance. Their expressions are filled with determination and wonder as they navigate through the enchanting landscape.', 'action_sequence': 'The adventurers move forward, excitement sparkling in their eyes as they uncover hidden treasures.'}, {'start': 135.44, 'text': 'Q is for the quest that we pursue R is for the rewards that are due S is for the smiles that break through T is for the triumphs in view', 'scene_description': 'In a lush, enchanted forest, adventurers dressed in earthy cloaks embark on a thrilling quest. The atmosphere is thick with mystery, with beams of sunlight filtering through the canopy, illuminating their eager faces. The air is filled with the sounds of nature and the thrill of discovery.', 'action_sequence': 'The adventurers stride ahead, eyes gleaming with excitement as they uncover hidden treasures in the forest.'}, {'start': 140.44, 'text': 'Q is for the quest that we pursue R is for the rewards that are due S is for the smiles that break through T is for the triumphs in view', 'scene_description': 'In a mystical forest, a group of adventurers dressed in deep green cloaks embarks on an exciting quest. Sunlight streams through the trees, creating a magical atmosphere. Their faces are filled with determination and joy as they navigate the enchanting landscape.', 'action_sequence': 'The adventurers move forward, eyes sparkling with excitement as they uncover hidden treasures along their path.'}, {'start': 142.4, 'text': 'U is for the universe of possibilities V is for the victory in the little victories W is for the wonder that frees X is for the extraordinary breeze', 'scene_description': 'Under a starlit sky, dreamers gather on a hilltop, their faces glowing with hope. Dressed in flowing robes, they release lanterns into the night, each symbolizing a wish. The soft rustle of the breeze and the twinkling stars create an atmosphere of wonder and possibility.', 'action_sequence': 'The lanterns rise into the night sky, illuminating the darkness as they carry dreams into the universe.'}, {'start': 147.4, 'text': 'U is for the universe of possibilities V is for the victory in the little victories W is for the wonder that frees X is for the extraordinary breeze', 'scene_description': 'Under a canopy of stars, dreamers gather on a hilltop, their faces aglow with hope. Dressed in flowing robes, they release lanterns into the night sky, each representing a cherished wish. The gentle breeze rustles through the grass, enhancing the magical atmosphere.', 'action_sequence': 'The lanterns ascend, lighting up the night as they float away, carrying dreams into the cosmos.'}, {'start': 152.4, 'text': 'U is for the universe of possibilities V is for the victory in the little victories W is for the wonder that frees X is for the extraordinary breeze', 'scene_description': 'Beneath a starry sky, dreamers gather on a hilltop, their faces illuminated with hope. Clad in flowing robes, they release lanterns into the night, each symbolizing a heartfelt wish. The soft rustling of the breeze and twinkling stars create an enchanting atmosphere of wonder.', 'action_sequence': 'The lanterns rise, illuminating the night as they drift away, carrying dreams into the universe.'}, {'start': 157.4, 'text': 'U is for the universe of possibilities V is for the victory in the little victories W is for the wonder that frees X is for the extraordinary breeze', 'scene_description': 'Under a starlit sky, dreamers gather on a hilltop, their faces aglow with hope. Dressed in flowing robes, they release lanterns into the night, each symbolizing a wish. The soft rustle of the breeze and twinkling stars create a sense of wonder.', 'action_sequence': 'The lanterns rise, illuminating the night as they float away, carrying dreams into the universe.'}, {'start': 162.4, 'text': 'U is for the universe of possibilities V is for the victory in the little victories W is for the wonder that frees X is for the extraordinary breeze', 'scene_description': 'Under a celestial sky, dreamers gather on a hilltop, their faces glowing with hope. Clad in flowing robes, they release lanterns into the night, each representing a wish. The gentle breeze whispers through the trees, creating a magical atmosphere of wonder.', 'action_sequence': 'The lanterns ascend, lighting up the night as they float away, carrying dreams into the cosmos.'}, {'start': 167.4, 'text': 'U is for the universe of possibilities V is for the victory in the little victories W is for the wonder that frees X is for the extraordinary breeze', 'scene_description': 'Under a starlit sky, dreamers gather on a hilltop, their faces aglow with hope. Dressed in flowing robes, they release lanterns into the night, each symbolizing a wish. The soft rustle of the breeze and twinkling stars create an atmosphere of wonder and possibility.', 'action_sequence': 'The lanterns rise into the night sky, illuminating the darkness as they carry dreams into the universe.'}, {'start': 172.4, 'text': 'U is for the universe of possibilities V is for the victory in the little victories W is for the wonder that frees X is for the extraordinary breeze', 'scene_description': 'Under a celestial sky, dreamers gather on a hilltop, their faces glowing with hope. Clad in flowing robes, they release lanterns into the night, each representing a wish. The gentle breeze whispers through the trees, creating a magical atmosphere of wonder.', 'action_sequence': 'The lanterns ascend, lighting up the night as they float away, carrying dreams into the cosmos.'}, {'start': 177.4, 'text': 'Y is for the zest to live fully each day Z is for the zeal that comes into play With this alphabet of joy, I find my way Celebrating life, come what may', 'scene_description': 'In a vibrant marketplace, people of all backgrounds come together to celebrate life. Colorful stalls overflow with fresh produce and handmade crafts. The air is alive with music and laughter, as everyone, dressed in bright clothing, embodies the zest for life and community.', 'action_sequence': 'People dance joyfully in the streets, sharing food and laughter as they celebrate together.'}, {'start': 183.4, 'text': 'Y is for the zest to live fully each day Z is for the zeal that comes into play With this alphabet of joy, I find my way Celebrating life, come what may', 'scene_description': 'In a lively marketplace, people from all walks of life gather to celebrate. Stalls brim with colorful produce and handmade crafts, while the air is filled with the sounds of music and laughter. Everyone wears vibrant attire, radiating joy and enthusiasm.', 'action_sequence': 'People dance in the streets, sharing food and joy as they celebrate life together.'}, {'start': 188.4, 'text': 'Y is for the zest to live fully each day Z is for the zeal that comes into play With this alphabet of joy, I find my way Celebrating life, come what may', 'scene_description': 'In a bustling marketplace, people of diverse backgrounds come together to celebrate life. Colorful stalls overflow with fresh produce and handmade crafts. The atmosphere is electric with music and laughter, as everyone, dressed in vibrant clothing, embodies the zest for life.', 'action_sequence': 'People dance joyfully in the streets, sharing food and laughter as they celebrate together.'}, {'start': 193.4, 'text': 'Y is for the zest to live fully each day Z is for the zeal that comes into play With this alphabet of joy, I find my way Celebrating life, come what may', 'scene_description': 'In a lively marketplace, people of all backgrounds celebrate life together. Colorful stalls overflow with fresh produce and handmade crafts. The energy is infectious, with music playing and laughter ringing out, as everyone wears bright clothing, embodying the zest for life.', 'action_sequence': 'People dance in the streets, sharing food and joy as they celebrate life together.'}, {'start': 198.4, 'text': 'Y is for the zest to live fully each day Z is for the zeal that comes into play With this alphabet of joy, I find my way Celebrating life, come what may', 'scene_description': 'In a vibrant marketplace, people from all walks of life gather to celebrate. Stalls brim with colorful produce and handmade crafts, while the air is filled with the sounds of music and laughter. Everyone wears bright attire, radiating joy and enthusiasm.', 'action_sequence': 'People dance joyfully in the streets, sharing food and laughter as they celebrate life together.'}]\n",
      "Loading initial pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A mixture of bf16 and non-bf16 filenames will be loaded.\n",
      "Loaded bf16 filenames:\n",
      "[transformer/diffusion_pytorch_model.bf16-00002-of-00003.safetensors, vae/diffusion_pytorch_model.bf16.safetensors, transformer/diffusion_pytorch_model.bf16-00001-of-00003.safetensors, transformer/diffusion_pytorch_model.bf16-00003-of-00003.safetensors]\n",
      "Loaded non-bf16 filenames:\n",
      "[text_encoder/model-00002-of-00002.safetensors, text_encoder/model-00001-of-00002.safetensors\n",
      "If this behavior is not expected, please check your folder structure.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bcc3b131949442e89a2c58e1ad20f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a9ef9412a0d431ab008e9394a166d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing VAE\n",
      "Quantizing text encoder\n",
      "Quantizing transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A mixture of bf16 and non-bf16 filenames will be loaded.\n",
      "Loaded bf16 filenames:\n",
      "[transformer/diffusion_pytorch_model.bf16-00002-of-00003.safetensors, vae/diffusion_pytorch_model.bf16.safetensors, transformer/diffusion_pytorch_model.bf16-00001-of-00003.safetensors, transformer/diffusion_pytorch_model.bf16-00003-of-00003.safetensors]\n",
      "Loaded non-bf16 filenames:\n",
      "[text_encoder/model-00002-of-00002.safetensors, text_encoder/model-00001-of-00002.safetensors\n",
      "If this behavior is not expected, please check your folder structure.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading quantized pipeline\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b6c76490904d1a914fb65036a2e601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene 1 has 1 segments\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'image_input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# run and curate images for scenes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m audio_file \u001b[38;5;129;01min\u001b[39;00m CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_files\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mcreate_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 490\u001b[0m, in \u001b[0;36mcreate_video\u001b[0;34m()\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_video\u001b[39m():\n\u001b[1;32m    489\u001b[0m     config, scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp \u001b[38;5;241m=\u001b[39m process_all_audios(audio_file, CONFIG)\n\u001b[0;32m--> 490\u001b[0m     \u001b[43mprocess_audio_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscenes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_images_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio_videos_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlast_end_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_images_dir: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_images_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maudio_videos_dir: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_videos_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 473\u001b[0m, in \u001b[0;36mprocess_audio_video\u001b[0;34m(config, scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp)\u001b[0m\n\u001b[1;32m    470\u001b[0m         video_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvideo_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(video_num)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(j\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    471\u001b[0m         video_output_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(audio_videos_dir, video_name)\n\u001b[0;32m--> 473\u001b[0m         generate_video(video_pipe, prompt, \u001b[43mimage_input\u001b[49m, video_filename\u001b[38;5;241m=\u001b[39mvideo_output_path)\n\u001b[1;32m    474\u001b[0m         video_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Increment video number for the next segment\u001b[39;00m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'image_input' is not defined"
     ]
    }
   ],
   "source": [
    "# run and curate images for scenes\n",
    "for audio_file in CONFIG[\"audio_files\"]:\n",
    "    create_video()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
