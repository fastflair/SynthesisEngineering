{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26aff409-35ee-4abd-9520-134911b6aa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import einops\n",
    "import gc\n",
    "import imageio\n",
    "import imageio_ffmpeg\n",
    "import json\n",
    "import math\n",
    "import moviepy as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import safetensors.torch as sf\n",
    "import time\n",
    "import torch\n",
    "import traceback\n",
    "import transformers\n",
    "import whisper\n",
    "\n",
    "from datetime import datetime\n",
    "from diffusers import AutoencoderKLHunyuanVideo\n",
    "from diffusers_helper.bucket_tools import find_nearest_bucket\n",
    "from diffusers_helper.clip_vision import hf_clip_vision_encode\n",
    "from diffusers_helper.hunyuan import encode_prompt_conds, vae_decode, vae_encode, vae_decode_fake\n",
    "from diffusers_helper.memory import cpu, gpu, get_cuda_free_memory_gb, move_model_to_device_with_memory_preservation, offload_model_from_device_for_memory_preservation\n",
    "from diffusers_helper.memory import fake_diffusers_current_device, DynamicSwapInstaller, unload_complete_models, load_model_as_complete\n",
    "from diffusers_helper.models.hunyuan_video_packed import HunyuanVideoTransformer3DModelPacked\n",
    "from diffusers_helper.pipelines.k_diffusion_hunyuan import sample_hunyuan\n",
    "from diffusers_helper.thread_utils import AsyncStream, async_run\n",
    "from diffusers_helper.utils import save_bcthw_as_mp4, crop_or_pad_yield_mask, soft_append_bcthw, resize_and_center_crop, state_dict_weighted_merge, state_dict_offset_merge, generate_timestamp\n",
    "from hdi1 import HiDreamImagePipeline\n",
    "from hdi1 import HiDreamImageTransformer2DModel\n",
    "from hdi1.schedulers.fm_solvers_unipc import FlowUniPCMultistepScheduler\n",
    "from hdi1.schedulers.flash_flow_match import FlashFlowMatchEulerDiscreteScheduler\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "from transformers import LlamaForCausalLM, PreTrainedTokenizerFast\n",
    "from transformers import LlamaModel, CLIPTextModel, LlamaTokenizerFast, CLIPTokenizer\n",
    "from transformers import SiglipImageProcessor, SiglipVisionModel\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype = torch.bfloat16\n",
    "MAX_SEED = np.iinfo(np.int32).max\n",
    "retry_limit = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc04bc-5cb1-48a7-b2e8-3eb80404c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "THEME = \"music video animation, spiritual, intimate, beautiful, grooving with God\"\n",
    "CONFIG = {\n",
    "    \"openai_api_key\": \"\",\n",
    "    \"openai_model\": \"gpt-4o-mini\",\n",
    "    \"openai_model_small_reasoning\": \"o1-mini\",\n",
    "    \"openai_model_large\": \"gpt-4o\",\n",
    "    \"hf_token\": \"\",\n",
    "    \"base_working_dir\": \"./images\",\n",
    "    \"base_video_dir\": \"./output\",\n",
    "    \"audio_files\": [\n",
    "        \"/mnt/d/Share/Audio/Vibe Groovin with God.flac\",    \n",
    "    ],\n",
    "    \"device\": device,\n",
    "    \"dtype\": dtype,\n",
    "    \"retry_limit\": retry_limit,\n",
    "    \"MAX_SEED\": MAX_SEED,\n",
    "}\n",
    "\n",
    "HEIGHT = 540\n",
    "WIDTH = 960\n",
    "\n",
    "MODEL_PREFIX = \"azaneko\"\n",
    "LLAMA_MODEL_NAME = \"hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4\"\n",
    "\n",
    "# Model configurations\n",
    "MODEL_CONFIGS = {\n",
    "    \"dev\": {\n",
    "        \"path\": f\"{MODEL_PREFIX}/HiDream-I1-Dev-nf4\",\n",
    "        \"guidance_scale\": 0.0,\n",
    "        \"num_inference_steps\": 28,\n",
    "        \"shift\": 6.0,\n",
    "        \"scheduler\": FlashFlowMatchEulerDiscreteScheduler\n",
    "    },\n",
    "    \"full\": {\n",
    "        \"path\": f\"{MODEL_PREFIX}/HiDream-I1-Full-nf4\",\n",
    "        \"guidance_scale\": 5.0,\n",
    "        \"num_inference_steps\": 50,\n",
    "        \"shift\": 3.0,\n",
    "        \"scheduler\": FlowUniPCMultistepScheduler\n",
    "    },\n",
    "    \"fast\": {\n",
    "        \"path\": f\"{MODEL_PREFIX}/HiDream-I1-Fast-nf4\",\n",
    "        \"guidance_scale\": 0.0,\n",
    "        \"num_inference_steps\": 16,\n",
    "        \"shift\": 3.0,\n",
    "        \"scheduler\": FlashFlowMatchEulerDiscreteScheduler\n",
    "    }\n",
    "}\n",
    "model_type = \"dev\"\n",
    "\n",
    "outputs_folder = './temp_outputs/'\n",
    "os.makedirs(outputs_folder, exist_ok=True)\n",
    "\n",
    "# Ensure base directories exist\n",
    "os.makedirs(CONFIG[\"base_working_dir\"], exist_ok=True)\n",
    "os.makedirs(CONFIG[\"base_video_dir\"], exist_ok=True)\n",
    "\n",
    "SCENE_DESCRIPTIONS = '''scene_description: boris vallejo style, frank frazetta style, 8k high quality digital painting, masterpiece, very detailed, ultra realistic, (best quality) very detailed epic masterpiece, detailed face, full body, wrinkly wizard toad reading an ancient scroll in a swamp, best quality, epic scene, Dungeons and dragons atmosphere, heroic fantasy, realistic, realism, full body\n",
    "scene_description: masterpiece, best quality, amazing quality ,solo, holding, closed_mouth, sitting, outdoors, sky, day, cloud, water, blurry, blue_sky, tree, orange_eyes, no_humans, blurry_background, fish, reflection, mountain, animal_focus, lake, fishing_rod, reflective_water, fishing, holding_fishing_rod, fishing_line,A digital illustration shoot from the side about a cute cartoon fish character sitting on a wooden pier by a calm lake, holding a fishing rod. the image also shows a serene mountain landscape with tall trees and a clear blue sky. on the middle of the image, a no human, furry, blue and orange fish with large, expressive eyes and a happy expression is sitting on the wooden pier. the fish appears to be a chubby, cartoonish creature with a slim body and a closed mouth. it is facing the viewer with its eyes looking to the side. the creature is holding the fishing rod in its right hand and its left hand is resting on the edge of the water. the background features a mountain range with a few clouds in the sky, and the water is calm and still. the lighting is soft and natural, creating a peaceful and serene atmosphere. solo, looking at viewer, closed mouth, sitting, brown eyes, outdoors, sky, day, cloud, holding, tree, blue sky, water, tree branch, holding stick, mountain, fish, pond, holding fishing rod\n",
    "scene_description: masterpiece, best quality, good quality, very awa, newest, highres, absurdres, 1girl, solo, dress, standing, flower, outdoors, water, white flower, pink flower, scenery, reflection, rain, dark, ripples, yellow flower, puddle, colorful, abstract, standing on liquid, very Wide Shot, limited palette,\n",
    "scene_description: masterpiece, best quality, amazing quality, klskx, nsfw, explicit, 1girl, redhead, open fridge, dim blue fridge light, nude, oversized t-shirt slipping off shoulder, panties, barefoot, messy hair, licking fingers, one hand on hip, standing by fridge, looking back, midnight snack indoors, kitchen, wooden floor, open fridge door, scattered snacks, napkin, night, dark shadows, high contrast, volumetric lighting, intricate details, blurry background, depth of field\n",
    "scene_description: time travel, holding coffee,, hdr, 8k, absurdres, shiny, outdoors, reflection, blurry, blurry background, tokyo lights,tokyo street, neon lights, cyberpunk, high-contrast lighting, intricate details, vibrant colors, reflective surfaces, futuristic urban environment, glowing neon signs, cybernetic enhancements, punk aesthetic, dynamic pose, dynamic composition, depth of field, dark_theme, detailed backgroud, foreshortening, blurry edges, vignetting\n",
    "scene_description: masterpiece, best quality, amazing quality ,solo, yellow_eyes, flower, outdoors, sky, cloud, tree, no_humans, night, animal, facial_mark, moon, cat, star_\\(sky\\), night_sky, full_moon, starry_sky, animal_focus, architecture, black_cat, east_asian_architecture, whiskers, black_fur, huge_moon,A digital illustration shoot from a front camera angle about a cute black cat sitting on a moss-covered branch under a large full moon, surrounded by a fantasy setting with tall pagodas and flowers. on the middle of the image, a 1girl, who appears to be a cat, is sitting, looking at the viewer with large, expressive brown eyes. the cat has black fur with yellow stripes, and its ears are perked up, giving it a curious expression. it is positioned on the branch, with its body facing the viewer, giving a clear view of its full body. in the background, a full moon is visible, with stars twinkling in the night sky, and fluffy white clouds are visible, adding to the magical atmosphere of the scene. the overall style is whimsical and fantastical, with a focus on the cat's curious expression and the intricate details of its markings on its body. solo, smile, brown eyes, flower, outdoors, sky, day, cloud, no humans, animal, night, animal focus, star \\(sky\\), moon, cat, full moon\n",
    "scene_description: hyper realistic, a majestic A gemstone stag slowly blooming into life, moss and flowers sprouting from cracks in its crystalline body as it awakens, its eyes, initially dull stones, begin to glow with an inner emerald light, dawn light filters through a forest, illuminating the stags nascent awakening, wide shot capturing the stags full form and the blooming flora with golden antlers standing in a sunlit clearing, surrounded by ethereal forest spirits, glowing flora, magical atmosphere, extremely high-resolution details, photographic, realism pushed to extreme, fine texture, incredibly lifelike, Cinematic, beautiful, vibrant, masterpiece, 32k, ultra HD, ultra-detailed, amazing quality, amazing artist, sharp edges, detailed textures, full view, atmospheric lighting, amazing visuals\n",
    "scene_description: impressive and grotesque scenery on a distant world, famous artwork inspired by jordan grimmer, dramatic scene, fractal art, 1990s fantasy style, dynamic angle, this image shows the enormous transcendent hydra-like beast known as the powerful jadesnap as it wriggleflomps from the izzled depths of a churning, otherworldly glowing sea under a dramatic tempestuous sky, it is surrounded by the typical jagged fractal rock formations on the crinkled shore of the water-rich planet \"zoffeldirly quartus,\" superstitious life forms call it \"the bringer of lost keys\", creature focus, very aesthetic, extremely detailed, ultra high resolution, 8k, 4k, harmonising colors, light beige and chartreuse and bordeaux red and indigo blue and byzantium purple and ebony black, ovg, in the style of ck-ovf, amanoer, arsmjstyle, dnddarkestfantasy, aidmafluxpro1.1\n",
    "scene_description: A realistic toilet, completely engulfed in flames, inferno, blazing, concept art, masterpiece, perfect lighting, purple and pink flames, realistic flames, 8k, absurdres, massive fire - rendered in the highest quality, realistic bathroom background, A3ther\n",
    "scene_description: intricate linework with expressive contrasts, soft lighting with dynamic highlights, young woman wearing flight goggles, aviator leather jacket, long loose platinum hair, standing next to a 1930s biplane on an airstrip surrounded by tropical jungle, sunset, in orange hues\n",
    "scene_description: 1 girl , ghost girl , grave stone , hugging , kneeling , tear , raining , masterpiece, best quality, good quality, very awa, newest, highres, absurdres\n",
    "scene_description: Indi_and_Digo,1girl,solo,furry,tail,source_furry,,red hair,purple fur, purple eyes, child, kid, masterpiece, best quality, female hand holding a small umbrella, miniature wet tiny mouse standing on the path, rain, drops, funny, intricate details, hyper-realistic, hyper-detailed, professional photoshoot, colorful, ultra-sharp, vivid color, chiaroscuro lighting, macro\n",
    "scene_description: masterpiece, best quality, good quality, very aesthetic, absurdres, newest, 8K, depth of field, in the style of cknc, artist:moriimee, in the style of cksc, 1girl, short golden hair, bob cut, blue eyes, large breasts, bouncy, baggy red tank top, sagging, oversized leggings, sweat-soaked, soft moan, looking up, from below, hiking on ridge, pressing breasts through tank, nipples outlined BREAK mountain ridge, rocky path, whistling wind, pine scent BREAK warm light, high contrast, earthy tones, depth of field, golden hour lighting, rich details, rugged allure\n",
    "scene_description: masterpiece, best quality, good quality, very aesthetic, absurdres, newest, 8K, depth of field, in the style of cknc, artist:moriimee, in the style of cksc, 1girl, short green hair, tangled, hazel eyes, medium breasts, firm, hooded cloak, glossy skin, picking lock, smirking, looking at viewer, from side BREAK twilight forest, mossy ruins, owls hooting BREAK dynamic light, green tones, high contrast, twilight glow, rich details, sneaky atmosphere\n",
    "scene_description: A digital art splash in the style of bo-cyborgsplash, a mysterious raven character positioned in the center of the frame, directly facing the viewer, the raven's upper body is close to the camera, showcasing its dark, ornate attire adorned with intricate details and glowing purple gemstones, its long beak is visible, and its piercing pink eyes seem to lock onto the viewer with a sense of intensity, the background is a dark, neon-lit space with glowing elements, creating a mystical atmosphere, the character is adorned with numerous gemstone necklaces, adding a touch of opulence to the overall design, the overall effect is one of intrigue and mystery, a fantastic abstract colorful art splash, high quality, ultra detailed\n",
    "scene_description: masterpiece, best quality, good quality, very aesthetic, absurdres, newest, 8K, depth of field, in the style of cknc, artist:moriimee, in the style of cksc, 1girl, long grey hair, wild, stormy eyes, large breasts, round, thunderbolt crown, glossy skin, summoning lightning, looking at viewer, from below BREAK stormy cliff, dark clouds, waves crashing BREAK dynamic light, blue tones, high contrast, electric glow, rich details, dramatic atmosphere\n",
    "scene_description: masterpiece, hyper detailed, high quality v3, ultra-HD details, 16k, midjourneyv6.1, (Pencil_Sketch:1.2, messy lines, greyscale, traditional media, sketch), anime, manga, sketch, unfinished, hatching texture, fullbody portrait, long legs, mustard XXDFace head, creepy smile, x-eyes, robot joints, wearing ((creepy beige victorian tattered, broken, cracked, dirt, ripped dress)) at night, in 22@SIT_BCN wide street, creepy red moonlight, perfect anatomy\n",
    "scene_description: masterpiece, best quality, good quality, very awa, newest, highres, absurdres, 1girl, solo, short hair, blonde hair, red eyes, holding, standing, belt, hood, water, scarf, arm up, torn clothes, plant, hood up, wading, partially submerged, mittens, pillar, torch, holding torch, limited palette\n",
    "scene_description: anthropomorphic corgi knight, corgi head, on one knee, planted sword, holding sword, plate armor, scowl, v-shaped eyebrows ,cloudy, godrays, sunshine, riverbank background, holy halo ,wide shot, depth of field, realism, no humans, animal focus, corpses,covered in blood, battlefield\n",
    "scene_description: 1girl,solo,furry,pink fur,tail,ears,source_furry, child, kid, masterpiece, best quality, long hair, twin braids, farmer outfit,(steampunk), goggles, googles on head, bag, wheat field, outdoors, wind, accordion, holding instrument, playing instrument, gloves, wheat, sunset, farm, house, scenery, landscape, blurry, blurry background, looking at viewer, smile\n",
    "scene_description: masterpiece, best quality, amazing quality, solo, sitting, no humans, glowing, wariza, robot, science fiction, on floor, electricity, cable, joints, robot joints, damaged, mechanical parts, wire, humanoid robot, screw, bolt, Countless lightning, electric shock, open mouth, Open five fingers,hands up, Bent back, Low Angle\n",
    "scene_description: cinema scene, photograph, 4k photorealistic, beautiful sexy girl, NSFW, see through sheer, breasts exposed, brown eyes, pink hair, light makeup, red lips, large breasts, glowing necklace, pink ballgown, lactation, lactating, double peace sign, plunging neckline, smile, snow, outdoors, east asian architecture, night\n",
    "scene_description: A close-up of an avian alien with feathers that change color depending on its emotions, intricate plumage patterns with metallic sheen, and sharp, beak-like appendages that subtly shift shape.\n",
    "scene_description: A warm, lively Irish bar with rustic wooden beams, vintage pub signs, and soft amber lighting. Behind the counter stands an anthropomorphic cat dressed in a casual bartender outfit — rolled-up sleeves, vest, and flat cap — pouring a beer from a bottle into a pint glass with careful precision. The bar top is polished wood, lined with empty glasses and old whiskey bottles. The atmosphere is cozy and inviting, with a touch of old-world charm. In the background, shelves of liquor and a mirror reflect the soft golden glow of the room. The scene is full of character and detail, capturing the charm of a traditional Irish pub\n",
    "scene_description: a naked woman with long hair, transparent wet shirt, can see her beautiful breasts, no panties seen, her legs covering her crotch, sits in a chair, lewd pose. diffused natural lighting from a nearby window, sensual, revealing, tender.\n",
    "scene_description: The high resolution image depicts an underwater castle with intricate architecture, reminiscent of a fairy tale, lying on the sand below. The castle is adorned with domes, spires, and ornate carvings, all in shades of blue and white. It is surrounded by vibrant coral reefs and various marine life, including colorful seashells and bubbles floating around. The scene is bathed in soft, natural light filtering down from above, creating a magical and serene atmosphere. The castle appears to be a blend of Gothic and fantasy styles, with a grand entrance and delicate details that suggest a world of enchantment beneath the waves.\n",
    "scene_description: perfect quality, bokeh effect, photography, an ancient, cloaked female figure with piercing eyes, face covered in dust and dirt, their face wrapped in fabric adorned with extremely intricate hieroglyphs, set against an abstract, polygonal blue gradient background. The cloth appears worn and frayed\n",
    "scene_description: A NSFW Snapchat explicit iPhone selfie photo It's of a very pretty and attractive girl, whose a blonde, and has a good, hourglass figure, her boobs are out and she is complety naked, smiling at the camera with her head tilted, her upper body only is visible in the image, her boobs are out and she is complety naked, as it is a selfie in a carseat, candid, vertical 9:16 aspect ratio.\n",
    "scene_description: The image depicts a beautifully ornate, oval-shaped clear glass sphere with an intricately designed frame. The frame is made of a golden material with elaborate, swirling patterns. Inside the sphere there is a detailed, red and white dragon emerging from what appears to be water or waves made of crystal. The dragon has a majestic and mythical appearance, with flowing, spiky hair and a fierce expression. The background of the sphere shows a dynamic scene with splashing water and waves, adding to the sense of movement and energy. The sphere is mounted on a tree trunk, and there are pink flowers and green foliage surrounding it, enhancing the natural and mystical atmosphere of the scene.\n",
    "scene_description: A cute monster with a rainbow-colored fur coat, a long tail, and big, round eyes. The monster is sitting on a cluttered shelf in a mysterious, dark environment. The shelf is surrounded by other colorful monsters, some of which are sleeping, while others are playing with toys. The environment is ultra-detailed, with intricate carvings on the walls and floors, and a perfect cinematic lighting that highlights every detail. The product photography is perfect, capturing every angle and texture of the monster and its surroundings. The environment is perfect for a horror movie, with a sense of foreboding and danger lurking around every corner. The scene is rendered in 8K, with every pixel perfectly defined and crisp.\n",
    "scene_description: A (glistening crystal eye:1.3) is embedded in the bark of a soaked oak tree, its (surface refracting raindrops:1.0) like glass marbles on velvet. The forest around it is (bathed in muted blue lightning:0.8), and nearby crows sit motionless, their feathers (glowing faintly at the edges:0.5), as if time paused mid-rain\n",
    "scene_description: A stunningly intricate mechanical steampunk timeart gold crow perches gracefully on a gnarled tree branch, its piercing gaze fixed directly upon the viewer, body with spinning gears. The creature's eyes are exquisitely detailed, reflecting the ethereal glow of a dark nebula that shimmers in the background. Soft bokeh adds an air of mystery to this captivating scene.\n",
    "scene_description: The image depicts a fantastical scene set in a lush, enchanted forest. The focal point is a delicate, ethereal creature that appears to be a blend of plant and humanoid form. This creature has a translucent, almost glass-like body with intricate, vein-like patterns running throughout. Its limbs and torso are slender and elongated, giving it an otherworldly appearance. The creature's head is rounded with large, luminous yellow eyes that seem to glow softly, adding to its mystical aura. It has small, pointed ears or antennae protruding from its head, enhancing its otherworldly look. The creature's skin is a gradient of translucent hues, with subtle red accents at various points, particularly around its joints and the inside base of its body. Surrounding the creature are two large, glowing flowers that resemble lotus flowers. These flowers have a soft, ethereal light emanating from their centers, with petals that are a gradient of white to light pink. The flowers are connected to the creature by slender, elongated stems that are also translucent and veined. The background is a dense, verdant forest with a soft, diffused light filtering through the canopy, creating a mystical and serene atmosphere. The ground is covered in moss, small plants, and fallen leaves, adding to the natural, enchanted setting.\n",
    "scene_description: A shadowy, humanoid figure floats above scorched earth. No armor, only black smoke and swirling darkness form its body. Occasional red or violet glows inside. Stormy sky above.\n",
    "scene_description: Photograph of a big green orc in a heavy metal tshirt sitting in a rocking chair on a porch and playing a classical guitar,Photographed with a cinematic 50mm lens\n",
    "scene_description: The image shows a tabby cat standing behind a wooden fence in a field. The cat is holding a bouquet of colorful flowers, including purple and white daisies, and some other small flowers. The background is a lush, green field with various wildflowers and plants.\n",
    "'''\n",
    "\n",
    "ACTION_SEQUENCES = f'''action_sequence: The man dances energetically, leaping mid-air with fluid arm swings and quick footwork,\n",
    "action_sequence: The girl dances gracefully, with clear movements, full of charm.\n",
    "action_sequence: The girl suddenly took out a sign that said “cute” using right hand\n",
    "action_sequence: The girl skateboarding, repeating the endless spinning and dancing and jumping on a skateboard, with clear movements, full of charm.\n",
    "action_sequence: The man dances flamboyantly, swinging his hips and striking bold poses with dramatic flair.\n",
    "action_sequence: The woman dances elegantly among the blossoms, spinning slowly with flowing sleeves and graceful hand movements.\n",
    "action_sequence: The young man writes intensely, flipping papers and adjusting his glasses with swift, focused movements.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf4bd5-3db3-406e-b81c-6666c01b6b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def reset_memory(device):\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats(device)\n",
    "    torch.cuda.reset_accumulated_memory_stats(device)\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "def load_models(model_type: str):\n",
    "    config = MODEL_CONFIGS[model_type]\n",
    "    \n",
    "    tokenizer_4 = PreTrainedTokenizerFast.from_pretrained(LLAMA_MODEL_NAME)\n",
    "    \n",
    "    text_encoder_4 = LlamaForCausalLM.from_pretrained(\n",
    "        LLAMA_MODEL_NAME,\n",
    "        output_hidden_states=True,\n",
    "        output_attentions=True,\n",
    "        return_dict_in_generate=True,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "    transformer = HiDreamImageTransformer2DModel.from_pretrained(\n",
    "        config[\"path\"],\n",
    "        subfolder=\"transformer\",\n",
    "        torch_dtype=torch.bfloat16\n",
    "    )\n",
    "    \n",
    "    pipe = HiDreamImagePipeline.from_pretrained(\n",
    "        config[\"path\"],\n",
    "        scheduler=FlowUniPCMultistepScheduler(num_train_timesteps=1000, shift=config[\"shift\"], use_dynamic_shifting=False),\n",
    "        tokenizer_4=tokenizer_4,\n",
    "        text_encoder_4=text_encoder_4,\n",
    "        torch_dtype=torch.bfloat16,\n",
    "    )\n",
    "    pipe.transformer = transformer\n",
    "    pipe.enable_sequential_cpu_offload()\n",
    "\n",
    "    del(tokenizer_4)\n",
    "    del(text_encoder_4)\n",
    "    del(transformer)\n",
    "    \n",
    "    return pipe, config\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate_image(pipe: HiDreamImagePipeline, model_type: str, prompt: str, negative_prompt : str, resolution: tuple[int, int], seed: int):\n",
    "    # Get configuration for current model\n",
    "    prompt = \"masterpiece, \" + prompt\n",
    "    config = MODEL_CONFIGS[model_type]\n",
    "    guidance_scale = config[\"guidance_scale\"]\n",
    "    num_inference_steps = config[\"num_inference_steps\"]\n",
    "    \n",
    "    # Parse resolution\n",
    "    height, width = resolution\n",
    " \n",
    "    # Handle seed\n",
    "    if seed == -1:\n",
    "        seed = torch.randint(0, MAX_SEED, (1,)).item()\n",
    "    \n",
    "    generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "    \n",
    "    images = pipe(\n",
    "        prompt,\n",
    "        negative_prompt,\n",
    "        height=height,\n",
    "        width=width,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_inference_steps=num_inference_steps,\n",
    "        num_images_per_prompt=1,\n",
    "        generator=generator\n",
    "    ).images\n",
    "    \n",
    "    return images[0], seed\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_video(\n",
    "    text_encoder, text_encoder_2, image_encoder, vae, transformer, tokenizer, tokenizer_2, feature_extractor, high_vram,\n",
    "    output_video: str,\n",
    "    input_image: np.ndarray,\n",
    "    prompt: str,\n",
    "    n_prompt: str,\n",
    "    seed: int,\n",
    "    total_second_length: float,\n",
    "    latent_window_size: int,\n",
    "    steps: int,\n",
    "    cfg: float,\n",
    "    gs: float,\n",
    "    rs: float,\n",
    "    gpu_memory_preservation: int,\n",
    "    use_teacache: bool,\n",
    "    mp4_crf: int\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Synchronous video generation. Returns a list of MP4 filenames\n",
    "    (one per latent section, final video last).\n",
    "    \"\"\"\n",
    "    # compute sections\n",
    "    total_latent_sections = int(max(round((total_second_length * 30) / (latent_window_size * 4)), 1))\n",
    "    job_id = generate_timestamp()\n",
    "    out_files: list[str] = []\n",
    "\n",
    "    try:\n",
    "        # unload if low VRAM\n",
    "        if not high_vram:\n",
    "            unload_complete_models(text_encoder, text_encoder_2, image_encoder, vae, transformer)\n",
    "\n",
    "        # --- TEXT ENCODING ---\n",
    "        if not high_vram:\n",
    "            fake_diffusers_current_device(text_encoder, gpu)\n",
    "            load_model_as_complete(text_encoder_2, target_device=gpu)\n",
    "\n",
    "        llama_vec, clip_l_pooler = encode_prompt_conds(\n",
    "            prompt, text_encoder, text_encoder_2, tokenizer, tokenizer_2\n",
    "        )\n",
    "\n",
    "        if cfg == 1:\n",
    "            llama_vec_n = torch.zeros_like(llama_vec)\n",
    "            clip_l_pooler_n = torch.zeros_like(clip_l_pooler)\n",
    "        else:\n",
    "            llama_vec_n, clip_l_pooler_n = encode_prompt_conds(\n",
    "                n_prompt, text_encoder, text_encoder_2, tokenizer, tokenizer_2\n",
    "            )\n",
    "\n",
    "        llama_vec, llama_attention_mask     = crop_or_pad_yield_mask(llama_vec, length=512)\n",
    "        llama_vec_n, llama_attention_mask_n = crop_or_pad_yield_mask(llama_vec_n, length=512)\n",
    "\n",
    "        # --- IMAGE PREPROCESS & VAE ENCODE ---\n",
    "        H, W, C = input_image.shape\n",
    "        height, width = find_nearest_bucket(H, W, resolution=640)\n",
    "        input_image_np = resize_and_center_crop(input_image, target_width=width, target_height=height)\n",
    "        Image.fromarray(input_image_np).save(os.path.join(outputs_folder, f\"{job_id}.png\"))\n",
    "\n",
    "        # <-- FIXED: add a singleton 'frames' dim so shape is [1, C, 1, H, W]\n",
    "        input_image_pt = torch.from_numpy(input_image_np).float() / 127.5 - 1\n",
    "        input_image_pt = input_image_pt.permute(2, 0, 1)[None, :, None, :, :]\n",
    "\n",
    "        if not high_vram:\n",
    "            load_model_as_complete(vae, target_device=gpu)\n",
    "        start_latent = vae_encode(input_image_pt, vae)\n",
    "\n",
    "        # --- CLIP VISION ENCODE ---\n",
    "        if not high_vram:\n",
    "            load_model_as_complete(image_encoder, target_device=gpu)\n",
    "        clip_out = hf_clip_vision_encode(input_image_np, feature_extractor, image_encoder)\n",
    "        image_encoder_last_hidden_state = clip_out.last_hidden_state\n",
    "\n",
    "        # cast to transformer dtype\n",
    "        llama_vec                         = llama_vec.to(transformer.dtype)\n",
    "        llama_vec_n                       = llama_vec_n.to(transformer.dtype)\n",
    "        clip_l_pooler                     = clip_l_pooler.to(transformer.dtype)\n",
    "        clip_l_pooler_n                   = clip_l_pooler_n.to(transformer.dtype)\n",
    "        image_encoder_last_hidden_state   = image_encoder_last_hidden_state.to(transformer.dtype)\n",
    "\n",
    "        # --- PREPARE SAMPLING ---\n",
    "        rnd = torch.Generator(\"cpu\").manual_seed(seed)\n",
    "        num_frames = latent_window_size * 4 - 3\n",
    "\n",
    "        history_latents = torch.zeros((1, 16, 1 + 2 + 16, height // 8, width // 8), dtype=torch.float32).cpu()\n",
    "        history_pixels = None\n",
    "        total_generated = 0\n",
    "\n",
    "        latent_paddings = list(reversed(range(total_latent_sections)))\n",
    "        if total_latent_sections > 4:\n",
    "            latent_paddings = [3] + [2] * (total_latent_sections - 3) + [1, 0]\n",
    "\n",
    "        # --- SAMPLING LOOP ---\n",
    "        for pad in latent_paddings:\n",
    "            is_last = (pad == 0)\n",
    "            pad_size = pad * latent_window_size\n",
    "            print(f\"Section pad={pad}, is_last={is_last}\")\n",
    "\n",
    "            indices = torch.arange(0, sum([1, pad_size, latent_window_size, 1, 2, 16])).unsqueeze(0)\n",
    "            (pre_idx, blank_idx, latent_idx,\n",
    "             post_idx, idx2x, idx4x\n",
    "            ) = indices.split([1, pad_size, latent_window_size, 1, 2, 16], dim=1)\n",
    "            clean_idx = torch.cat([pre_idx, post_idx], dim=1)\n",
    "\n",
    "            clean_pre_latents = start_latent.to(history_latents.device)\n",
    "            post, mid2, mid4 = history_latents[:, :, :1 + 2 + 16, :, :].split([1, 2, 16], dim=2)\n",
    "            clean_latents = torch.cat([clean_pre_latents, post], dim=2)\n",
    "\n",
    "            if not high_vram:\n",
    "                unload_complete_models()\n",
    "                move_model_to_device_with_memory_preservation(\n",
    "                    transformer, target_device=gpu, preserved_memory_gb=gpu_memory_preservation\n",
    "                )\n",
    "\n",
    "            transformer.initialize_teacache(enable_teacache=use_teacache, num_steps=steps)\n",
    "\n",
    "            gen_latents = sample_hunyuan(\n",
    "                transformer=transformer,\n",
    "                sampler='unipc',\n",
    "                width=width, height=height,\n",
    "                frames=num_frames,\n",
    "                real_guidance_scale=cfg,\n",
    "                distilled_guidance_scale=gs,\n",
    "                guidance_rescale=rs,\n",
    "                num_inference_steps=steps,\n",
    "                generator=rnd,\n",
    "                prompt_embeds=llama_vec,\n",
    "                prompt_embeds_mask=llama_attention_mask,\n",
    "                prompt_poolers=clip_l_pooler,\n",
    "                negative_prompt_embeds=llama_vec_n,\n",
    "                negative_prompt_embeds_mask=llama_attention_mask_n,\n",
    "                negative_prompt_poolers=clip_l_pooler_n,\n",
    "                device=gpu, dtype=torch.bfloat16,\n",
    "                image_embeddings=image_encoder_last_hidden_state,\n",
    "                latent_indices=latent_idx,\n",
    "                clean_latents=clean_latents,\n",
    "                clean_latent_indices=clean_idx,\n",
    "                clean_latents_2x=mid2,\n",
    "                clean_latent_2x_indices=idx2x,\n",
    "                clean_latents_4x=mid4,\n",
    "                clean_latent_4x_indices=idx4x,\n",
    "            )\n",
    "\n",
    "            if is_last:\n",
    "                gen_latents = torch.cat([start_latent.to(gen_latents), gen_latents], dim=2)\n",
    "\n",
    "            total_generated += gen_latents.shape[2]\n",
    "            history_latents = torch.cat([gen_latents.to(history_latents), history_latents], dim=2)\n",
    "\n",
    "            if not high_vram:\n",
    "                offload_model_from_device_for_memory_preservation(\n",
    "                    transformer, target_device=gpu, preserved_memory_gb=8\n",
    "                )\n",
    "                load_model_as_complete(vae, target_device=gpu)\n",
    "\n",
    "            real_latents = history_latents[:, :, :total_generated, :, :]\n",
    "\n",
    "            if history_pixels is None:\n",
    "                history_pixels = vae_decode(real_latents, vae).cpu()\n",
    "            else:\n",
    "                section_len = (latent_window_size * 2 + 1) if is_last else (latent_window_size * 2)\n",
    "                overlap = latent_window_size * 4 - 3\n",
    "                curr_pixels = vae_decode(real_latents[:, :, :section_len], vae).cpu()\n",
    "                history_pixels = soft_append_bcthw(curr_pixels, history_pixels, overlap)\n",
    "\n",
    "            if not high_vram:\n",
    "                unload_complete_models()\n",
    "\n",
    "            out_name = os.path.join(outputs_folder, f\"{job_id}_{total_generated}.mp4\")\n",
    "            save_bcthw_as_mp4(history_pixels, out_name, fps=30, crf=mp4_crf)\n",
    "            out_files.append(out_name)\n",
    "\n",
    "            print(f\"Saved: {out_name}\")\n",
    "            if is_last:\n",
    "                out_name = output_video\n",
    "                save_bcthw_as_mp4(history_pixels, out_name, fps=30, crf=mp4_crf)\n",
    "                print(f\"Saved last: {out_name}\")\n",
    "                break\n",
    "\n",
    "    except Exception:\n",
    "        traceback.print_exc()\n",
    "        if not high_vram:\n",
    "            unload_complete_models(text_encoder, text_encoder_2, image_encoder, vae, transformer)\n",
    "\n",
    "    return out_files\n",
    "\n",
    "def synthesize_videos(text_encoder, text_encoder_2, image_encoder, vae, transformer, tokenizer, tokenizer_2, feature_extractor, high_vram,\n",
    "                      output_video: str, input_image: str, prompt: str, total_second_length: float):\n",
    "    # load and convert your test image\n",
    "    pil_img = Image.open(input_image)\n",
    "    input_np = np.array(pil_img)\n",
    "    # call our refactored generator\n",
    "    files = generate_video(\n",
    "        text_encoder, text_encoder_2, image_encoder, vae, transformer, tokenizer, tokenizer_2, feature_extractor, high_vram,\n",
    "        output_video = output_video,\n",
    "        input_image=input_np,\n",
    "        prompt=prompt,\n",
    "        n_prompt=\"\",\n",
    "        seed=random.randrange(0, 2**31),\n",
    "        total_second_length=total_second_length,\n",
    "        latent_window_size=9,\n",
    "        steps=25,\n",
    "        cfg=1.0,\n",
    "        gs=10.0,\n",
    "        rs=0.0,\n",
    "        gpu_memory_preservation=6,\n",
    "        use_teacache=False,\n",
    "        mp4_crf=1\n",
    "    )\n",
    "    final_video = files[-1] if files else None\n",
    "\n",
    "    return final_video\n",
    "\n",
    "def get_openai_prompt_response(\n",
    "    prompt: str,\n",
    "    config: dict,\n",
    "    max_tokens: int = 6000,\n",
    "    temperature: float = 0.33,\n",
    "    openai_model: str = \"\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Sends a prompt to OpenAI's API and retrieves the response with retry logic.\n",
    "    \"\"\"\n",
    "    client = OpenAI(api_key=config[\"openai_api_key\"])\n",
    "    response = client.chat.completions.create(\n",
    "        max_tokens=max_tokens,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"\"\"Act as a helpful assistant, you are an expert editor.\"\"\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        model=openai_model or config[\"openai_model\"],\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    retry_count = 0\n",
    "    while retry_count < config[\"retry_limit\"]:\n",
    "        try:\n",
    "            message_content = response.choices[0].message.content\n",
    "            return message_content\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            retry_count += 1\n",
    "            if retry_count == config[\"retry_limit\"]:\n",
    "                print(\"Retry limit reached. Moving to the next iteration.\")\n",
    "                return \"\"\n",
    "            else:\n",
    "                print(f\"Retrying... (Attempt {retry_count}/{config['retry_limit']})\")\n",
    "                time.sleep(1)  # Optional: wait before retrying\n",
    "\n",
    "def create_scenes(text: str, video_summary: str, config: dict):\n",
    "    \"\"\"\n",
    "    Creates scenes based on the extracted lyrics using OpenAI's API.\n",
    "    \"\"\"\n",
    "    # Generate scenes JSON\n",
    "    prompt = f'''Create a json list of diverse, unique scenes (groupings of text), scene_description, and action_sequence (100 words or less) from the following text.  Scenes should be groups of lyrics with new scenes when the lyric context changes.  Text: {text}   \n",
    "The json list should have the start value for the first item in the scene and the text that is combined for all items in the same scene.  \n",
    "The scene_description should include A vivid, sensory-rich, and unique visual description (100 words or less), including:\n",
    "  - Attire, setting, mood, lighting, and composition\n",
    "  - Artistic style (e.g., graphic novel, watercolor, oil painting, surrealist CGI)\n",
    "  - Powerful symbolism and metaphor; religious/spiritual analogies when relevant\n",
    "  - If people are present, focus on a closeup of a single anthropomorphic or highly stylized character, never multiple people in a closeup\n",
    "  - Favor semi-nude (e.g., sheer, translucent), natural forms, or artistically beautiful horror, as contextually appropriate\n",
    "  - Emphasize strong emotion, artistic genius, spiritual energy, and grandeur\n",
    "  - Special effects and CGI (glowing eyes, magical energy, electric auras, shifting reality, surreal environments, etc.)\n",
    "  - Unexpected, awe-inspiring, or haunting elements; scenes should be visually striking and imaginative\n",
    "  - No cliché or generic visual tropes; each scene must stand out and avoid repetition with others\n",
    "  \n",
    "The action_sequence should Describe slow, cinematic, and poetic actions (one or two sentences):\n",
    "  - Avoid sudden or fast movement, abrupt zooms, walking, dancing, shopping, or human group behaviors\n",
    "  - Action should be minimal, atmospheric, and enhance the emotional tone; favor symbolic gestures, stillness, or gradual transformations\n",
    "  - No scene transitions; each scene is self-contained\n",
    "  \n",
    "These are example scene_descriptions: {SCENE_DESCRIPTIONS}\n",
    "These are example action_sequences: {ACTION_SEQUENCES}  \n",
    "The desired general theme or style is: {THEME}\n",
    "Return only the json list, less jargon. The json list fields should be: start, text, scene_description, action_sequence'''\n",
    "\n",
    "    result = get_openai_prompt_response(prompt, config, openai_model=config[\"openai_model\"], temperature=0.85)\n",
    "    result = result.replace(\"```\", \"\").replace(\"```json\\n\", \"\").replace(\"json\\n\", \"\").replace(\"\\n\", \"\")\n",
    "    scenes = json.loads(result)\n",
    "    return scenes\n",
    "\n",
    "def revise_scenes(scenes, config: dict):\n",
    "    \"\"\"\n",
    "    Revise scenes based on the extracted scenes.\n",
    "    \"\"\"\n",
    "    # Generate scenes JSON\n",
    "    prompt = f'''Revise the JSON scenes to update the scene_description and action_sequence to engage the senses and imagination, suitable for creating a stunning, cinematic video experience.  We want unique scenes, even ones in the same sequence. Use descriptions of special effects in the scenes.  JSON scenes: {scenes}   \n",
    "The scene_description should include A vivid, sensory-rich, and unique visual description (100 words or less), including:\n",
    "  - Attire, setting, mood, lighting, and composition\n",
    "  - Artistic style (e.g., graphic novel, watercolor, oil painting, surrealist CGI)\n",
    "  - Powerful symbolism and metaphor; religious/spiritual analogies when relevant\n",
    "  - If people are present, focus on a closeup of a single anthropomorphic or highly stylized character, never multiple people in a closeup\n",
    "  - Favor semi-nude (e.g., sheer, translucent), natural forms, or artistically beautiful horror, as contextually appropriate\n",
    "  - Emphasize strong emotion, artistic genius, spiritual energy, and grandeur\n",
    "  - Special effects and CGI (glowing eyes, magical energy, electric auras, shifting reality, surreal environments, etc.)\n",
    "  - Unexpected, awe-inspiring, or haunting elements; scenes should be visually striking and imaginative\n",
    "  - No cliché or generic visual tropes; each scene must stand out and avoid repetition with others\n",
    "  \n",
    "The action_sequence should Describe slow, cinematic, and poetic actions (one or two sentences):\n",
    "  - Avoid sudden or fast movement, abrupt zooms, walking, dancing, shopping, or human group behaviors\n",
    "  - Action should be minimal, atmospheric, and enhance the emotional tone; favor symbolic gestures, stillness, or gradual transformations\n",
    "  \n",
    "Only update the scene_description and action_sequence. We do not want to have similar scene_descriptions and action_sequences for consecutive scenes, we want unique scenes that tell a brilliant, cohesive story.  Please update the scene_description and action_sequence to be different, creative, and consistent.  \n",
    "Do not delete any items as having scenes with the given start times are important. \n",
    "The desired general theme or style is: {THEME}\n",
    "Return only the json list, less jargon. The json list fields should be: start, text, scene_description, action_sequence'''\n",
    "\n",
    "    result = get_openai_prompt_response(prompt, config, openai_model=config[\"openai_model\"], temperature=0.33)\n",
    "    result = result.replace(\"```\", \"\").replace(\"```json\\n\", \"\").replace(\"json\\n\", \"\").replace(\"\\n\", \"\")\n",
    "    scenes = json.loads(result)\n",
    "    return scenes\n",
    "\n",
    "def get_audio_duration(audio_file):\n",
    "    with AudioFileClip(audio_file) as clip:\n",
    "        return clip.duration  # duration in seconds (float)\n",
    "\n",
    "def process_audio_scenes(audio_file: str, config: dict):\n",
    "    # set maximum duration for an image basis, should be in intervals of video generation length\n",
    "    max_duration_seconds  = 24\n",
    "    \"\"\"\n",
    "    Processes a single audio file through the entire workflow.\n",
    "    \"\"\"\n",
    "    # Create unique identifier based on audio file name\n",
    "    audio_basename = os.path.splitext(os.path.basename(audio_file))[0]\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    unique_id = f\"{audio_basename}_{timestamp}\"\n",
    "\n",
    "    # Create unique directories for images and videos\n",
    "    print(f\"Create unique directories for images and videos\")\n",
    "    audio_images_dir = os.path.join(config[\"base_working_dir\"], unique_id)\n",
    "    audio_videos_dir = os.path.join(config[\"base_video_dir\"], unique_id)\n",
    "    os.makedirs(audio_images_dir, exist_ok=True)\n",
    "    os.makedirs(audio_videos_dir, exist_ok=True)\n",
    "\n",
    "    # Step 1: Transcribe audio using Whisper\n",
    "    print(f\"Transcribe audio using Whisper\")\n",
    "    model = whisper.load_model(\"turbo\")\n",
    "    result = model.transcribe(audio_file)\n",
    "\n",
    "    # Cleanup Whisper model memory\n",
    "    del model\n",
    "    reset_memory(device)\n",
    "\n",
    "    segments = result['segments']\n",
    "\n",
    "    # Extract list of start times and texts\n",
    "    segment_texts_and_start_times = [(segment['text'].strip(), segment['start']) for segment in segments]\n",
    "\n",
    "    # Combine texts\n",
    "    text = \"\"\n",
    "    for segment_text, start in segment_texts_and_start_times:\n",
    "        text += f\"Start: {start}, Text: {segment_text}\\n\"\n",
    "\n",
    "    #last_end_value = segments[-1]['end']\n",
    "    last_end_value = float(get_audio_duration(audio_file))\n",
    "\n",
    "    # Path to scenes.json file\n",
    "    scenes_file_path = os.path.join(audio_images_dir, \"scenes.json\")\n",
    "\n",
    "    # Check if scenes.json exists\n",
    "    if os.path.exists(scenes_file_path):\n",
    "        print(f\"Scenes file already exists at {scenes_file_path}. Skipping scene generation.\")\n",
    "        with open(scenes_file_path, \"r\") as scenes_file:\n",
    "            scenes = json.load(scenes_file)\n",
    "        return scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp\n",
    "\n",
    "    # Step 2: Generate video summary using OpenAI\n",
    "    print(f\"Generate video summary using OpenAI\")\n",
    "    video_summary_prompt = f'Create a short summary that describes a music video based on these lyrics: {text}'\n",
    "    video_summary = get_openai_prompt_response(video_summary_prompt, config, openai_model=config[\"openai_model\"])\n",
    "\n",
    "    # Step 3: Create scenes based on lyrics\n",
    "    print(f\"Create scenes based on lyrics\")\n",
    "    try:\n",
    "        scenes = create_scenes(text, video_summary, config)\n",
    "    except:\n",
    "        try:\n",
    "            scenes = create_scenes(text, video_summary, config)\n",
    "        except:\n",
    "            try:\n",
    "                scenes = create_scenes(text, video_summary, config)\n",
    "            except: \n",
    "                return \"\", audio_images_dir, audio_videos_dir, last_end_value, timestamp\n",
    "\n",
    "    # we don't want scenes longer than 18 seconds\n",
    "    new_scenes = []\n",
    "    for i in range(len(scenes)):\n",
    "        scene = scenes[i]\n",
    "        if i == 0:\n",
    "            start_time = 0\n",
    "        else:\n",
    "            start_time = scene['start']\n",
    "            print(f'start_time: {start_time}')\n",
    "        # Determine the end time\n",
    "        if i < len(scenes) - 1:\n",
    "            end_time = scenes[i + 1]['start']\n",
    "        else:\n",
    "            end_time = last_end_value\n",
    "        duration = end_time - start_time\n",
    "        # Split the scene if duration exceeds max_duration_seconds\n",
    "        while duration > max_duration_seconds:\n",
    "            new_scene = scene.copy()\n",
    "            new_scene['start'] = start_time\n",
    "            new_scenes.append(new_scene)\n",
    "            start_time += max_duration_seconds\n",
    "            duration = end_time - start_time\n",
    "        # Append the remaining part of the scene\n",
    "        if duration > 0:\n",
    "            new_scene = scene.copy()\n",
    "            new_scene['start'] = start_time\n",
    "            new_scenes.append(new_scene)\n",
    "    # Replace the original scenes with the new list\n",
    "    scenes = new_scenes\n",
    "    # improve the scenes with a revision\n",
    "    try:\n",
    "        scenes_revised = revise_scenes(scenes, config)\n",
    "        scenes = scenes_revised\n",
    "        print(f'revised scenes')\n",
    "    except:\n",
    "        try:\n",
    "            scenes_revised = revise_scenes(scenes, config)\n",
    "            scenes = scenes_revised\n",
    "            print(f'revised scenes')\n",
    "        except:\n",
    "            print('cannot revise scenes')\n",
    "            \n",
    "    \n",
    "    # Save the scenes to scenes.json\n",
    "    with open(scenes_file_path, \"w\") as scenes_file:\n",
    "        json.dump(scenes, scenes_file)\n",
    "        \n",
    "    return scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp\n",
    "\n",
    "\n",
    "def process_audio_images(config: dict, scenes, audio_images_dir):\n",
    "    # Step 4: Load HiDream pipeline and generate images\n",
    "    print(f\"Load HiDream pipeline and generate images\")\n",
    "    pipe, _ = load_models(model_type)\n",
    "    height = HEIGHT\n",
    "    width = WIDTH\n",
    "    resolution = (height, width)\n",
    "    guidance_scale = 3.9\n",
    "    num_inference_steps = 16\n",
    "    max_sequence_length = 512\n",
    "    seed = -1\n",
    "    negative_prompt = \"worst quality, low quality, worst aesthetic, old, blurry, lowres, signature, artist name, watermark, username, sketch, logo, furry, text, speech bubble\"\n",
    "\n",
    "    # Generate images for each scene\n",
    "    image_num = 1\n",
    "    for scene in scenes:\n",
    "        image_prompt = THEME+\". \"+scene['scene_description']\n",
    "        image, seed = generate_image(pipe, model_type, image_prompt, negative_prompt, resolution, seed)        \n",
    "        filename = f\"image_{str(image_num).zfill(2)}.jpg\"\n",
    "        image_path = os.path.join(audio_images_dir, filename)\n",
    "        image.save(image_path, dpi=(300, 300))\n",
    "        image_num += 1\n",
    "\n",
    "    # Move the pipeline back to CPU and delete it\n",
    "    del pipe\n",
    "    reset_memory(device)\n",
    "    return\n",
    "\n",
    "def process_audio_video(config: dict, scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp):\n",
    "    # Step 6: Load Video Pipeline\n",
    "    print(f\"Load Video Pipeline\")\n",
    "    # check GPU memory & decide offload strategy\n",
    "    free_mem_gb = get_cuda_free_memory_gb(gpu)\n",
    "    high_vram = free_mem_gb > 60\n",
    "    # load all models & tokenizers\n",
    "    text_encoder    = LlamaModel.from_pretrained(\"hunyuanvideo-community/HunyuanVideo\",\n",
    "                                                 subfolder=\"text_encoder\", torch_dtype=torch.float16).cpu()\n",
    "    text_encoder_2  = CLIPTextModel.from_pretrained(\"hunyuanvideo-community/HunyuanVideo\",\n",
    "                                                    subfolder=\"text_encoder_2\", torch_dtype=torch.float16).cpu()\n",
    "    tokenizer       = LlamaTokenizerFast.from_pretrained(\"hunyuanvideo-community/HunyuanVideo\",\n",
    "                                                          subfolder=\"tokenizer\")\n",
    "    tokenizer_2     = CLIPTokenizer.from_pretrained(\"hunyuanvideo-community/HunyuanVideo\",\n",
    "                                                     subfolder=\"tokenizer_2\")\n",
    "    vae             = AutoencoderKLHunyuanVideo.from_pretrained(\"hunyuanvideo-community/HunyuanVideo\",\n",
    "                                                                 subfolder=\"vae\", torch_dtype=torch.float16).cpu()\n",
    "    feature_extractor = SiglipImageProcessor.from_pretrained(\"lllyasviel/flux_redux_bfl\",\n",
    "                                                             subfolder=\"feature_extractor\")\n",
    "    image_encoder   = SiglipVisionModel.from_pretrained(\"lllyasviel/flux_redux_bfl\",\n",
    "                                                        subfolder=\"image_encoder\", torch_dtype=torch.float16).cpu()\n",
    "    transformer     = HunyuanVideoTransformer3DModelPacked.from_pretrained(\n",
    "                        \"lllyasviel/FramePackI2V_HY\", torch_dtype=torch.bfloat16).cpu()\n",
    "    # set eval & dtypes\n",
    "    for m in (text_encoder, text_encoder_2, image_encoder, vae, transformer):\n",
    "        m.eval()\n",
    "        m.requires_grad_(False)\n",
    "    transformer.high_quality_fp32_output_for_inference = True\n",
    "    transformer.to(dtype=torch.bfloat16)\n",
    "    vae.to(dtype=torch.float16)\n",
    "    image_encoder.to(dtype=torch.float16)\n",
    "    text_encoder.to(dtype=torch.float16)\n",
    "    text_encoder_2.to(dtype=torch.float16)\n",
    "    if not high_vram:\n",
    "        vae.enable_slicing()\n",
    "        vae.enable_tiling()\n",
    "        DynamicSwapInstaller.install_model(transformer, device=gpu)\n",
    "        DynamicSwapInstaller.install_model(text_encoder, device=gpu)\n",
    "    else:\n",
    "        text_encoder.to(gpu)\n",
    "        text_encoder_2.to(gpu)\n",
    "        image_encoder.to(gpu)\n",
    "        vae.to(gpu)\n",
    "        transformer.to(gpu)\n",
    "        \n",
    "    video_num = 1\n",
    "\n",
    "    # Step 7: Generate video sequences\n",
    "    for i, scene in enumerate(scenes):\n",
    "        prompt = scene[\"action_sequence\"]\n",
    "\n",
    "        # Use the initial image for each scene\n",
    "        image_input = os.path.join(audio_images_dir, f\"image_{str(i+1).zfill(2)}.jpg\")\n",
    "\n",
    "        # Calculate duration to keep the video in 6-second increments\n",
    "        if i + 1 < len(scenes):\n",
    "            next_start_time = scenes[i + 1][\"start\"]\n",
    "        else:\n",
    "            next_start_time = last_end_value  # Use the final ending time for the last scene\n",
    "\n",
    "        if i == 0:\n",
    "            duration = next_start_time\n",
    "        else:\n",
    "            duration = next_start_time - scene[\"start\"]\n",
    "\n",
    "        video_name = f\"v_fpk_{str(video_num).zfill(2)}_{str(i+1)}_{timestamp}.mp4\"\n",
    "        video_output_path = os.path.join(audio_videos_dir, video_name)\n",
    "        synthesize_videos(text_encoder, text_encoder_2, image_encoder, vae, transformer, tokenizer, tokenizer_2, feature_extractor, high_vram, \n",
    "            video_output_path, image_input, prompt, duration)    \n",
    "        time.sleep(1)  # Pause for 1 second\n",
    "        video_num += 1  # Increment video number for the next segment\n",
    "\n",
    "    # 1) Offload / unload all models from GPU\n",
    "    unload_complete_models(\n",
    "        text_encoder,\n",
    "        text_encoder_2,\n",
    "        image_encoder,\n",
    "        vae,\n",
    "        transformer\n",
    "    )\n",
    "    \n",
    "    del(text_encoder)\n",
    "    del(text_encoder_2)\n",
    "    del(tokenizer)\n",
    "    del(tokenizer_2)\n",
    "    del(vae)\n",
    "    del(feature_extractor)\n",
    "    del(image_encoder)\n",
    "    del(transformer)\n",
    "    \n",
    "    # 3) Force GC + CUDA clean‐up\n",
    "    reset_memory(gpu)\n",
    "    \n",
    "    return\n",
    "\n",
    "def process_all_audios(audio_file, config: dict):\n",
    "    \"\"\"\n",
    "    Processes a list of audio files through the workflow.\n",
    "    \"\"\"\n",
    "    print(f\"Processing audio file: {audio_file}\")\n",
    "    scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp = process_audio_scenes(audio_file, config)\n",
    "    print(f'{len(scenes)} scenes:\\n{json.dumps(scenes, indent=4)}')\n",
    "    print(f'last_end_value: {last_end_value} timestamp: {timestamp}')\n",
    "    # Create starting images for scenes\n",
    "    process_audio_images(config, scenes, audio_images_dir)\n",
    "    return config, scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp\n",
    "\n",
    "def create_video(config):\n",
    "    config, scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp = process_all_audios(audio_file, config)\n",
    "    process_audio_video(config, scenes, audio_images_dir, audio_videos_dir, last_end_value, timestamp)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a14c2-e285-4052-89d5-9861308f6a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run new systems\n",
    "for audio_file in CONFIG[\"audio_files\"]:\n",
    "    create_video(CONFIG)\n",
    "    reset_memory(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d529b-f72c-416b-af29-a91309a4c816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d570d04d-ce7c-47ae-98e9-403a69aecdb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
